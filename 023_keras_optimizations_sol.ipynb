{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PTC5srJ2bYG9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "#from tensorflow.keras import Sequential\n",
        "#from tensorflow.keras import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, InputLayer, Reshape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras import metrics\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kt2r1tfRg0cj"
      },
      "outputs": [],
      "source": [
        "# Helper to plot loss\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS8tDLiFbYG_"
      },
      "source": [
        "# Keras and Tensorflow Optimizations\n",
        "\n",
        "There are several things that we can do to make our networks a bit better. Unfortunately for much of this there aren't definitive answers for \"what is the best choice\", so we do have to do some trial and error, but we can use some guidelines to get us started in the right direction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQLYUA1XbYHB"
      },
      "source": [
        "## Load MNIST Data\n",
        "\n",
        "We can use the MNIST digit dataset for testing, since it is reasonably large. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGygrQlobYHC",
        "outputId": "e48ea85c-2032-4ddc-85bf-4a02dd76b7f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-21 13:30:18.384634: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.2240 - accuracy: 0.9345 - val_loss: 0.1094 - val_accuracy: 0.9681\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0892 - accuracy: 0.9729 - val_loss: 0.0975 - val_accuracy: 0.9689\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0579 - accuracy: 0.9825 - val_loss: 0.0944 - val_accuracy: 0.9726\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0410 - accuracy: 0.9872 - val_loss: 0.0867 - val_accuracy: 0.9732\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.0815 - val_accuracy: 0.9766\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0765 - val_accuracy: 0.9787\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0169 - accuracy: 0.9941 - val_loss: 0.1140 - val_accuracy: 0.9713\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0856 - val_accuracy: 0.9793\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0957 - val_accuracy: 0.9773\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.0863 - val_accuracy: 0.9806\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0817 - accuracy: 0.9800\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.08167178183794022, 0.9800000190734863]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 and 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "print(train_images.shape)\n",
        "\n",
        "train_labels = np_utils.to_categorical(train_labels)\n",
        "test_labels = np_utils.to_categorical(test_labels)\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsycEGiGbYHE"
      },
      "source": [
        "## Prequel - Saving and Loading Models\n",
        "\n",
        "As we've seen, models can take a long time to train in many cases. Like with the sklearn models, we can save and load ours as they are trained and reused. This is a pretty integral part of making neural network models usable, so it is pretty easy. \n",
        "\n",
        "In addition to this we often see models saved in the h5 format, which just saves slightly less stuff along with the model. If we are using models trained elsewhere this format is very common. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2PSIZDbbYHE",
        "outputId": "37aa2093-e7d5-4680-fac9-ba4045372d96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-21 13:31:49.544074: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_path/assets\n"
          ]
        }
      ],
      "source": [
        "# Save my model\n",
        "model.save('model_path')\n",
        "model = keras.models.load_model('model_path')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lEJgmNFYbYHE"
      },
      "outputs": [],
      "source": [
        "# Calling `save('my_model.h5')` creates a h5 file `my_model.h5`.\n",
        "model.save(\"my_h5_model.h5\")\n",
        "\n",
        "# It can be used to reconstruct the model identically.\n",
        "reconstructed_model = keras.models.load_model(\"my_h5_model.h5\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DoRkV4nTbYHF"
      },
      "source": [
        "## Network Size\n",
        "\n",
        "Probably the first question that we will think of when building networks through Tensorflow is \"how big should it be\"? This is a very big question, and one of those ones without a real answer. We can put some guidelines in place to help us though. \n",
        "\n",
        "### What Does the Size Mean?\n",
        "\n",
        "The size of a neural network is also known as the capacity. We can relate it roughly to the size of our first model, the tree. The larger a network is the higher its capacity to learn. This is similar to a tree, the larger the tree, the more fitted it can become to the training data. \n",
        "\n",
        "### What Size to Use\n",
        "\n",
        "We can start with a few guidelines to have a reasonably sized neural network. These steps do not ensure an optimal solution, but they'll get us started. There really is not a prescribed method for calculating the optimal network size (beleive me, I've looked), but there are several rules of thumb we can build together:\n",
        "\n",
        "<ul>\n",
        "<li> Start with an input layer that is either\n",
        "    <ul>\n",
        "    <li> The width of the data, if the feature set is relatively small. \n",
        "    <li> A reasonably large number if the feature set is large. \n",
        "    <li> We don't have a true diving line, but 512 is a reasonable value to try for an upper end, at least at first. \n",
        "    </ul>\n",
        "<li> Add 1 or 2 hidden layers of the same size and observe the results. We want to keep the model smaller if making it larger doesn't improve things, so first we shoudl see how good of a job a small model does. If the data is very large, skipping past the 1 layer step may save some time since we can predict that we can do better with a larger model in advance. \n",
        "<li> Increase layers of the same size until we get some overfitting and the training loss flattens. We want to reach the point where the model is getting to be excellent at predicting the training data. This is something we can see in the plot by noticing that the validation loss flatlines or starts to get worse. The training loss flattening is an indication that the model is not getting any better at learning the training data; we can use early stopping with a loose patience setting on training loss and lots of epochs to find this. \n",
        "<li> Add regularization steps to cut down that overfitting. We can try regularization and dropouts to cut down on that overfitting. We probably want to try a few options, parameters, and combinations here, there's not really a way to know in advance which regularization will work best on our data. \n",
        "<li> \"Funnel\" the layer size, potentially adding more layers. The traditional configuration of layers is to gradually decrease the size from the input layer towards the output layer. There is open debate on if this is better than having layers that are all the same size. We can play with this a little to see if results improve or not. \n",
        "<li> Use pruning. Much like a tree we can prune back a model to fight overfitting. \n",
        "</ul>\n",
        "\n",
        "### Height vs Width\n",
        "\n",
        "Another begged question is should we make networks wider (more neurons) or deeper (more layers)? Once again, there's no universal answer, but the general evidence leans towards more layers. There are several reasons for this, none of them definitive, but taken as a whole they add up to a strong case:\n",
        "\n",
        "<ul>\n",
        "<li> Ability to learn different representation of the data - this will be more clear next time when we start to look at some image specific neural networks, but one of the cool features of neural networks is that at each layer the network \"sees\" a different representation of the data, as it goes through each round of transformations. This has the effect of allowing it to identify different features at each layer, and use those features to make more and more accurate predictions. We'll examine this more soon. \n",
        "<li> Avoiding overfitting - extremely wide neural networks tend towards overfitting the training data and not generalizing as well to new data. \n",
        "<li> Ability to add interim steps - with a multi layer network we can add multiple steps such as regularization or dropouts, again to fight overfitting. \n",
        "<li> Automatic feature selection - deep neural networks will automatically perform a type of feature selection as the least important features are minimized in their importance. This is an emerging area of research - some people have argued that well designed neural networks can remove the need for feature selection, and neural networks are being created to be feature selection tools. We can see this illustrated most clearly with images again, we feed a network an entire image, and get a prediction. Note that this isn't a total rejection of feature selection for neural networks, improving the feature set will impact neural network models just as it will for ordinary models; with neural networks we just have the potential for the network to \"cover for mistakes\" in the features. This is more dramatic as data size and network size increase. \n",
        "<li> Results - deep learning has become a common term recently for a reason, due to the success of deep neural networks with many layers. Most of the cool stuff that we see coming from AI such as image recognition, translation, and self navigating robots are the result of deep learning networks. In practice these networks have tended to outperform shallower ones, especially in more complex tasks. \n",
        "</ul>\n",
        "\n",
        "Why not make a model that is both very wide and very deep? This will tend to overfit as it can \"memorize\" the training data. With large datasets we do see very large models in some cases, since the more data we have, the more fitting we can handle. With large datasets and huge models, the training time can potentially explode, so we have to be careful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-CRvieaiZI2",
        "outputId": "8c109988-428d-481d-d54e-b8eb1954cb2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 17s 10ms/step - loss: 0.2229 - accuracy: 0.9315 - val_loss: 0.1139 - val_accuracy: 0.9653\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.1070 - accuracy: 0.9674 - val_loss: 0.1123 - val_accuracy: 0.9669\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0830 - accuracy: 0.9754 - val_loss: 0.1034 - val_accuracy: 0.9698\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 17s 11ms/step - loss: 0.0700 - accuracy: 0.9778 - val_loss: 0.0876 - val_accuracy: 0.9768\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 16s 10ms/step - loss: 0.0615 - accuracy: 0.9817 - val_loss: 0.1112 - val_accuracy: 0.9676\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0523 - accuracy: 0.9841 - val_loss: 0.0871 - val_accuracy: 0.9780\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0473 - accuracy: 0.9850 - val_loss: 0.1109 - val_accuracy: 0.9749\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0443 - accuracy: 0.9865 - val_loss: 0.0981 - val_accuracy: 0.9786\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 17s 11ms/step - loss: 0.0405 - accuracy: 0.9881 - val_loss: 0.1058 - val_accuracy: 0.9778\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0403 - accuracy: 0.9880 - val_loss: 0.1108 - val_accuracy: 0.9778\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 17s 12ms/step - loss: 0.0377 - accuracy: 0.9890 - val_loss: 0.1171 - val_accuracy: 0.9779\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0351 - accuracy: 0.9896 - val_loss: 0.1326 - val_accuracy: 0.9767\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0306 - accuracy: 0.9910 - val_loss: 0.1140 - val_accuracy: 0.9792\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0367 - accuracy: 0.9899 - val_loss: 0.1356 - val_accuracy: 0.9758\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0320 - accuracy: 0.9910 - val_loss: 0.1350 - val_accuracy: 0.9782\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0280 - accuracy: 0.9924 - val_loss: 0.1484 - val_accuracy: 0.9762\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0354 - accuracy: 0.9911 - val_loss: 0.1210 - val_accuracy: 0.9793\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0252 - accuracy: 0.9929 - val_loss: 0.1271 - val_accuracy: 0.9808\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0293 - accuracy: 0.9925 - val_loss: 0.1657 - val_accuracy: 0.9757\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0297 - accuracy: 0.9926 - val_loss: 0.1384 - val_accuracy: 0.9793\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0276 - accuracy: 0.9931 - val_loss: 0.1438 - val_accuracy: 0.9794\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 0.1703 - val_accuracy: 0.9787\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.0286 - accuracy: 0.9928 - val_loss: 0.1431 - val_accuracy: 0.9800\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 23s 16ms/step - loss: 0.0279 - accuracy: 0.9934 - val_loss: 0.1648 - val_accuracy: 0.9768\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 0.1605 - val_accuracy: 0.9796\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0269 - accuracy: 0.9941 - val_loss: 0.1508 - val_accuracy: 0.9805\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0291 - accuracy: 0.9936 - val_loss: 0.1525 - val_accuracy: 0.9801\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 21s 14ms/step - loss: 0.0241 - accuracy: 0.9947 - val_loss: 0.1870 - val_accuracy: 0.9783\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0301 - accuracy: 0.9931 - val_loss: 0.1727 - val_accuracy: 0.9817\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 0.2301 - val_accuracy: 0.9793\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 17s 11ms/step - loss: 0.0275 - accuracy: 0.9941 - val_loss: 0.1701 - val_accuracy: 0.9826\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0244 - accuracy: 0.9937 - val_loss: 0.1648 - val_accuracy: 0.9834\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 24s 16ms/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 0.2076 - val_accuracy: 0.9803\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0305 - accuracy: 0.9939 - val_loss: 0.1933 - val_accuracy: 0.9787\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0253 - accuracy: 0.9949 - val_loss: 0.2313 - val_accuracy: 0.9793\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0288 - accuracy: 0.9945 - val_loss: 0.2127 - val_accuracy: 0.9793\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 17s 11ms/step - loss: 0.0313 - accuracy: 0.9941 - val_loss: 0.2397 - val_accuracy: 0.9795\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 0.2134 - val_accuracy: 0.9789\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 17s 12ms/step - loss: 0.0257 - accuracy: 0.9951 - val_loss: 0.1893 - val_accuracy: 0.9820\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 17s 11ms/step - loss: 0.0222 - accuracy: 0.9952 - val_loss: 0.2119 - val_accuracy: 0.9808\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.0264 - accuracy: 0.9950 - val_loss: 0.1919 - val_accuracy: 0.9810\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 21s 14ms/step - loss: 0.0240 - accuracy: 0.9953 - val_loss: 0.2403 - val_accuracy: 0.9808\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0199 - accuracy: 0.9958 - val_loss: 0.2257 - val_accuracy: 0.9810\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0222 - accuracy: 0.9955 - val_loss: 0.2419 - val_accuracy: 0.9818\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0228 - accuracy: 0.9957 - val_loss: 0.2638 - val_accuracy: 0.9808\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0308 - accuracy: 0.9953 - val_loss: 0.2322 - val_accuracy: 0.9826\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0225 - accuracy: 0.9958 - val_loss: 0.2387 - val_accuracy: 0.9828\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0286 - accuracy: 0.9950 - val_loss: 0.2960 - val_accuracy: 0.9790\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0249 - accuracy: 0.9960 - val_loss: 0.2505 - val_accuracy: 0.9822\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0227 - accuracy: 0.9959 - val_loss: 0.2092 - val_accuracy: 0.9812\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0200 - accuracy: 0.9961 - val_loss: 0.2470 - val_accuracy: 0.9808\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 17s 11ms/step - loss: 0.0284 - accuracy: 0.9957 - val_loss: 0.2520 - val_accuracy: 0.9821\n",
            "Epoch 53/100\n",
            "1083/1500 [====================>.........] - ETA: 4s - loss: 0.0241 - accuracy: 0.9956"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/px/vhm_920n7zx2wvqq_ht0q5tm0000gp/T/ipykernel_14855/614353106.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ml3950/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ml3950/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ml3950/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ml3950/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ml3950/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ml3950/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ml3950/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ml3950/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ml3950/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Model\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(784, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(784, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=100,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJkWGpsmbYHG",
        "outputId": "cda23fac-98c0-4d7d-d016-56d69a369bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2860 - accuracy: 0.9128 - val_loss: 0.1227 - val_accuracy: 0.9650\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1487 - accuracy: 0.9575 - val_loss: 0.1382 - val_accuracy: 0.9607\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1219 - accuracy: 0.9660 - val_loss: 0.1097 - val_accuracy: 0.9692\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0987 - accuracy: 0.9729 - val_loss: 0.1189 - val_accuracy: 0.9706\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0868 - accuracy: 0.9754 - val_loss: 0.1103 - val_accuracy: 0.9723\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0866 - accuracy: 0.9767 - val_loss: 0.1234 - val_accuracy: 0.9722\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0713 - accuracy: 0.9801 - val_loss: 0.1159 - val_accuracy: 0.9740\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.1409 - val_accuracy: 0.9717\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0651 - accuracy: 0.9829 - val_loss: 0.1205 - val_accuracy: 0.9741\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0602 - accuracy: 0.9840 - val_loss: 0.1175 - val_accuracy: 0.9765\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4adac2cfd0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Bigger Model\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=100,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmRw70jwga-g",
        "outputId": "c6dacb57-0449-40b7-e461-457f48745d70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3934 - accuracy: 0.8860 - val_loss: 0.1647 - val_accuracy: 0.9519\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1698 - accuracy: 0.9566 - val_loss: 0.1172 - val_accuracy: 0.9693\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1400 - accuracy: 0.9647 - val_loss: 0.1142 - val_accuracy: 0.9702\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1150 - accuracy: 0.9689 - val_loss: 0.1036 - val_accuracy: 0.9737\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0969 - accuracy: 0.9744 - val_loss: 0.1084 - val_accuracy: 0.9736\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0892 - accuracy: 0.9762 - val_loss: 0.1045 - val_accuracy: 0.9738\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0779 - accuracy: 0.9795 - val_loss: 0.0994 - val_accuracy: 0.9768\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0706 - accuracy: 0.9818 - val_loss: 0.1299 - val_accuracy: 0.9717\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0645 - accuracy: 0.9836 - val_loss: 0.1425 - val_accuracy: 0.9748\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0621 - accuracy: 0.9836 - val_loss: 0.1110 - val_accuracy: 0.9764\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4adaa62890>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tapered Model\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=100,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LwRjUyBMbYHG"
      },
      "source": [
        "## Epochs and Batch Sizes\n",
        "\n",
        "### Epochs\n",
        "\n",
        "Each epoch is a run through all of the training data. Epochs are simple, we can set a large number and use early stopping to cut things off when we've reached the best result. \n",
        "\n",
        "### Batch Sizes\n",
        "\n",
        "Batch size determines how many records are processed before the gradients are updated - i.e. the number of records between one forward and backwards pass. The batch sizes are a matter of very open debate for the optimal solution. At the high end, batch sizes are limited by what can fit in memory. When dealing with very large data this may matter as a batch that is a small fraction of the data may be a massive absolute size. At the lower end using smaller batches gives the same effect as it does when we looked at regular gradient descent - the gradients become less stable as we are relying on a smaller number of records. In reading more about batch sizes I want to update my recommendation to be even smaller than the 50 to 150 I suggested before, down to less than 100, even as small as into the single digits. There is research that smaller batch sizes tend to produce models that generalize better than ones with larger batches. \n",
        "\n",
        "Larger batch sizes do tend to be processed more quickly, sometimes substantially so, as the hardware is better able to be \"saturated\" with data to process. In big data scenarios, this can matter. One thing that you see in practice is that the GPUs (or similar) that are used to train neural networks have a certain amount of memory, and the batch size is limited by that memory. When doing something that involves large images or video, or similar, this can be a real area for concern. For us, these constraints won't really come up, but it's good to be aware of them. \n",
        "\n",
        "Dont' stress too much on batch size, this is really something that needs to be grid searched to find a great answer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMFYDxPdbYHG",
        "outputId": "bff27c4c-5d53-4d25-96f5-ef5c69444d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.3632 - accuracy: 0.6243 - val_loss: 0.4708 - val_accuracy: 0.8644\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.4782 - accuracy: 0.8542 - val_loss: 0.3032 - val_accuracy: 0.9104\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3432 - accuracy: 0.8988 - val_loss: 0.2371 - val_accuracy: 0.9313\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.2675 - accuracy: 0.9210 - val_loss: 0.2031 - val_accuracy: 0.9408\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.2285 - accuracy: 0.9333 - val_loss: 0.1755 - val_accuracy: 0.9490\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.1935 - accuracy: 0.9426 - val_loss: 0.1575 - val_accuracy: 0.9544\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.1706 - accuracy: 0.9490 - val_loss: 0.1425 - val_accuracy: 0.9594\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.1520 - accuracy: 0.9552 - val_loss: 0.1315 - val_accuracy: 0.9618\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.1361 - accuracy: 0.9601 - val_loss: 0.1230 - val_accuracy: 0.9643\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1247 - accuracy: 0.9642 - val_loss: 0.1163 - val_accuracy: 0.9655\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ada7b9710>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Big Batch\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=100,\n",
        "  batch_size=5000,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbJeAtnDipXo",
        "outputId": "e5abf716-b380-4174-f0df-9611e7689a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "24000/24000 [==============================] - 112s 5ms/step - loss: 0.3057 - accuracy: 0.9136 - val_loss: 0.1563 - val_accuracy: 0.9572\n",
            "Epoch 2/10\n",
            "24000/24000 [==============================] - 111s 5ms/step - loss: 0.2223 - accuracy: 0.9451 - val_loss: 0.1787 - val_accuracy: 0.9571\n",
            "Epoch 3/10\n",
            "24000/24000 [==============================] - 111s 5ms/step - loss: 0.2160 - accuracy: 0.9524 - val_loss: 0.1620 - val_accuracy: 0.9632\n",
            "Epoch 4/10\n",
            "24000/24000 [==============================] - 101s 4ms/step - loss: 0.2002 - accuracy: 0.9563 - val_loss: 0.1707 - val_accuracy: 0.9657\n",
            "Epoch 5/10\n",
            "24000/24000 [==============================] - 101s 4ms/step - loss: 0.2018 - accuracy: 0.9581 - val_loss: 0.1623 - val_accuracy: 0.9679\n",
            "Epoch 6/10\n",
            "24000/24000 [==============================] - 111s 5ms/step - loss: 0.1947 - accuracy: 0.9603 - val_loss: 0.2034 - val_accuracy: 0.9685\n",
            "Epoch 7/10\n",
            "24000/24000 [==============================] - 101s 4ms/step - loss: 0.1987 - accuracy: 0.9609 - val_loss: 0.1991 - val_accuracy: 0.9702\n",
            "Epoch 8/10\n",
            "24000/24000 [==============================] - 101s 4ms/step - loss: 0.1911 - accuracy: 0.9615 - val_loss: 0.1996 - val_accuracy: 0.9711\n",
            "Epoch 9/10\n",
            "24000/24000 [==============================] - 110s 5ms/step - loss: 0.1874 - accuracy: 0.9633 - val_loss: 0.2039 - val_accuracy: 0.9697\n",
            "Epoch 10/10\n",
            "24000/24000 [==============================] - 101s 4ms/step - loss: 0.1963 - accuracy: 0.9640 - val_loss: 0.2380 - val_accuracy: 0.9728\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ad7eb0e90>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Small Batch\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "# Note: Batch size of 2 is good to test\n",
        "# But it can take a VERY long time\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=100,\n",
        "  batch_size=8,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUFvtavwbYHH"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "Of all options the optimizer is the one we will care about the least. Each different optimizer is a different algorithm for doing the gradient descent. The optimizers have different results with respect to speed, memory usage, computational expense, and likelyhood to get stuck in a local minima. \n",
        "\n",
        "Adam is a good compromise between all factors and is very commonly used. We'll just use this for our work. One other common one is RMSprop, if you're feeling spicy, give that a try and see if there are any imporvements. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qIRrRF2bYHH"
      },
      "outputs": [],
      "source": [
        "optimizer_1 = tf.keras.optimizers.Adam()\n",
        "optimizer_2 = tf.keras.optimizers.RMSprop()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RXb18AySbYHH"
      },
      "source": [
        "## Activation \n",
        "\n",
        "Activation functions are the key to adding non-linearity to the network allowing it to learn complex and non-linear relationships in the data. We've used ReLU as the default and that is a solid choice in most cases. ReLU has one issue, the dying ReLU problem. This can happen when we get inputs to the activation function fall in the negative area. In short there can be neurons that \"die\" and never get updated again. These dead neurons are a problem as they now aren't contributing to the learning.\n",
        "\n",
        "![ReLU](images/relu.jpeg \"ReLU\")\n",
        "\n",
        "To combat the dying ReLU problem there are a couple of other activation functions that avoid that issue - Leaky ReLU and ELU. Each one changes the negative values to something other than 0 - Leaky ReLU uses a slight linear gradient, ELU uses an exponential function for a similar, but curved, slight gradient. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ81hFfxbYHH",
        "outputId": "d9a522ce-4252-4709-cb3a-c5cebfb1f355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.2731 - accuracy: 0.9181 - val_loss: 0.1513 - val_accuracy: 0.9543\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.1348 - accuracy: 0.9581 - val_loss: 0.1184 - val_accuracy: 0.9633\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.1060 - accuracy: 0.9666 - val_loss: 0.1175 - val_accuracy: 0.9663\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0905 - accuracy: 0.9720 - val_loss: 0.0970 - val_accuracy: 0.9725\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.0760 - accuracy: 0.9760 - val_loss: 0.0910 - val_accuracy: 0.9744\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.0682 - accuracy: 0.9784 - val_loss: 0.1130 - val_accuracy: 0.9689\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0655 - accuracy: 0.9791 - val_loss: 0.1047 - val_accuracy: 0.9716\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.0576 - accuracy: 0.9819 - val_loss: 0.1050 - val_accuracy: 0.9748\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.0606 - accuracy: 0.9812 - val_loss: 0.1068 - val_accuracy: 0.9725\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0560 - accuracy: 0.9826 - val_loss: 0.1116 - val_accuracy: 0.9725\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ad74e5650>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Take a leak \n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='leaky_relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='leaky_relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer=optimizer_2, loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi7DxgCsbYHH"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "The initialization provides the starting point for all the weights and bias values that we start out with. We initially started with random values in the scratch network - this is generally fine, but we can sometimes do better. \n",
        "\n",
        "### Imbalanced Weighting\n",
        "\n",
        "One application where initialization can help significantly is when dealing with imbalanced data. In this example of credit card fraud (real data that has been put through PCA), very, very few transactions are fraudulent. So we have a very imbalanced target value. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "jf84UJGPbYHI",
        "outputId": "8293e2c9-d3ae-45d7-a10d-30eeeeb95c1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6177101d-b415-47a4-97a1-9116d7f46065\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6177101d-b415-47a4-97a1-9116d7f46065')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6177101d-b415-47a4-97a1-9116d7f46065 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6177101d-b415-47a4-97a1-9116d7f46065');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file = tf.keras.utils\n",
        "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Count the Target Outcomes\n",
        "\n",
        "Credit card fraud is relatively rare, at least in view of the total number of transactions. We can count up the target values to see exactly what the expected skew is. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec08WeQEi_Fz",
        "outputId": "c35fb180-9017-4304-ce29-fd36ca25bfc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples:\n",
            "    Total: 284807\n",
            "    Positive: 492 (0.17% of total)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Bincount will count the number in each category\n",
        "neg, pos = np.bincount(raw_df['Class'])\n",
        "total = neg + pos\n",
        "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, pos, 100 * pos / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gr-lqY0tHwp"
      },
      "source": [
        "### We Have an Imbalance\n",
        "\n",
        "A big one. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5S02N45tGfu",
        "outputId": "27b8e170-e838-4c7d-adf1-b9013e4f9a6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0              0.0\n",
              "1              0.0\n",
              "2              1.0\n",
              "3              1.0\n",
              "4              2.0\n",
              "            ...   \n",
              "284802    172786.0\n",
              "284803    172787.0\n",
              "284804    172788.0\n",
              "284805    172788.0\n",
              "284806    172792.0\n",
              "Name: Time, Length: 284807, dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pop just removes a column. The equivalent of how we normally drop. \n",
        "# the TF docs commonly use this, so I've left it as is. \n",
        "cleaned_df = raw_df.copy()\n",
        "# You don't want the `Time` column.\n",
        "cleaned_df.pop('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3538h2djFHF"
      },
      "outputs": [],
      "source": [
        "# Use a utility from sklearn to split and shuffle your dataset.\n",
        "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
        "\n",
        "# Form np arrays of labels and features.\n",
        "train_labels = np.array(train_df.pop('Class'))\n",
        "test_labels = np.array(test_df.pop('Class'))\n",
        "\n",
        "train_features = np.array(train_df)\n",
        "test_features = np.array(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC5P3kaBjMwN",
        "outputId": "ed06c86d-234b-4045-b4fc-1c117eddf35a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training features shape: (227845, 29)\n",
            "Training labels shape: (227845,)\n",
            "Test features shape: (56962, 29)\n",
            "Test labels shape: (56962,)\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "#train_features = np.clip(train_features, -5, 5)\n",
        "#test_features = np.clip(test_features, -5, 5)\n",
        "\n",
        "print('Training features shape:', train_features.shape)\n",
        "print('Training labels shape:', train_labels.shape)\n",
        "print('Test features shape:', test_features.shape)\n",
        "print('Test labels shape:', test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtt_zz0HA6Jp"
      },
      "source": [
        "### Create a Biased Model\n",
        "\n",
        "As a side note, we can also specify a lot of different metrics to return, if we want to. \n",
        "\n",
        "The bias of the data is inserted in the model compilation step on the output layer. What does this do? It preconfigures the output layer to \"expect\" results to be this skewed. Recall that, along with the weight, the bias values are one of the things that is learned in training. By default the initial values are randomized, so the model needs to learn the skew towards the imbalance - if the balance between classes is moderate, that's not a big deal; if the balance is so drastically skewed in one direction, that's less practical. With the preset bias we can speed convergance and likely reduce loss. \n",
        "\n",
        "#### Other Imbalenced Work\n",
        "\n",
        "Other things that we looked at to improve balance such as under/over sampling still works with neural networks as it would with anything else. This is just one nn-specific thing that we can implement with minimal extra work. \n",
        "\n",
        "#### Metrics\n",
        "\n",
        "We can add a bunch of metrics to what we get returned by creating a list of the metrics that we want. Keras.metrics has a list, they are all the metrics we might expect. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO7R0L7XjTZv",
        "outputId": "1344b694-02cc-4855-8d0a-30cd56f4e6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2849/2849 [==============================] - 34s 10ms/step - loss: 0.0060 - tp: 150.0000 - fp: 31.0000 - tn: 181931.0000 - fn: 164.0000 - accuracy: 0.9989 - precision: 0.8287 - recall: 0.4777 - auc: 0.9005 - prc: 0.5935 - val_loss: 0.0029 - val_tp: 51.0000 - val_fp: 6.0000 - val_tn: 45496.0000 - val_fn: 16.0000 - val_accuracy: 0.9995 - val_precision: 0.8947 - val_recall: 0.7612 - val_auc: 0.9325 - val_prc: 0.7801\n",
            "Epoch 2/10\n",
            "2849/2849 [==============================] - 26s 9ms/step - loss: 0.0046 - tp: 177.0000 - fp: 37.0000 - tn: 181925.0000 - fn: 137.0000 - accuracy: 0.9990 - precision: 0.8271 - recall: 0.5637 - auc: 0.9257 - prc: 0.6744 - val_loss: 0.0026 - val_tp: 45.0000 - val_fp: 5.0000 - val_tn: 45497.0000 - val_fn: 22.0000 - val_accuracy: 0.9994 - val_precision: 0.9000 - val_recall: 0.6716 - val_auc: 0.9326 - val_prc: 0.8127\n",
            "Epoch 3/10\n",
            "2849/2849 [==============================] - 27s 9ms/step - loss: 0.0043 - tp: 195.0000 - fp: 35.0000 - tn: 181927.0000 - fn: 119.0000 - accuracy: 0.9992 - precision: 0.8478 - recall: 0.6210 - auc: 0.9210 - prc: 0.6941 - val_loss: 0.0029 - val_tp: 39.0000 - val_fp: 3.0000 - val_tn: 45499.0000 - val_fn: 28.0000 - val_accuracy: 0.9993 - val_precision: 0.9286 - val_recall: 0.5821 - val_auc: 0.9326 - val_prc: 0.8129\n",
            "Epoch 4/10\n",
            "2849/2849 [==============================] - 27s 10ms/step - loss: 0.0042 - tp: 186.0000 - fp: 24.0000 - tn: 181938.0000 - fn: 128.0000 - accuracy: 0.9992 - precision: 0.8857 - recall: 0.5924 - auc: 0.9273 - prc: 0.7161 - val_loss: 0.0026 - val_tp: 53.0000 - val_fp: 8.0000 - val_tn: 45494.0000 - val_fn: 14.0000 - val_accuracy: 0.9995 - val_precision: 0.8689 - val_recall: 0.7910 - val_auc: 0.9325 - val_prc: 0.8001\n",
            "Epoch 5/10\n",
            "2849/2849 [==============================] - 27s 9ms/step - loss: 0.0041 - tp: 196.0000 - fp: 38.0000 - tn: 181924.0000 - fn: 118.0000 - accuracy: 0.9991 - precision: 0.8376 - recall: 0.6242 - auc: 0.9339 - prc: 0.6924 - val_loss: 0.0025 - val_tp: 44.0000 - val_fp: 3.0000 - val_tn: 45499.0000 - val_fn: 23.0000 - val_accuracy: 0.9994 - val_precision: 0.9362 - val_recall: 0.6567 - val_auc: 0.9326 - val_prc: 0.8254\n",
            "Epoch 6/10\n",
            "2849/2849 [==============================] - 37s 13ms/step - loss: 0.0041 - tp: 192.0000 - fp: 34.0000 - tn: 181928.0000 - fn: 122.0000 - accuracy: 0.9991 - precision: 0.8496 - recall: 0.6115 - auc: 0.9306 - prc: 0.7141 - val_loss: 0.0026 - val_tp: 45.0000 - val_fp: 3.0000 - val_tn: 45499.0000 - val_fn: 22.0000 - val_accuracy: 0.9995 - val_precision: 0.9375 - val_recall: 0.6716 - val_auc: 0.9326 - val_prc: 0.8245\n",
            "Epoch 7/10\n",
            "2849/2849 [==============================] - 27s 9ms/step - loss: 0.0039 - tp: 190.0000 - fp: 33.0000 - tn: 181929.0000 - fn: 124.0000 - accuracy: 0.9991 - precision: 0.8520 - recall: 0.6051 - auc: 0.9355 - prc: 0.7171 - val_loss: 0.0025 - val_tp: 46.0000 - val_fp: 3.0000 - val_tn: 45499.0000 - val_fn: 21.0000 - val_accuracy: 0.9995 - val_precision: 0.9388 - val_recall: 0.6866 - val_auc: 0.9326 - val_prc: 0.8229\n",
            "Epoch 8/10\n",
            "2849/2849 [==============================] - 35s 12ms/step - loss: 0.0036 - tp: 208.0000 - fp: 31.0000 - tn: 181931.0000 - fn: 106.0000 - accuracy: 0.9992 - precision: 0.8703 - recall: 0.6624 - auc: 0.9451 - prc: 0.7607 - val_loss: 0.0024 - val_tp: 53.0000 - val_fp: 6.0000 - val_tn: 45496.0000 - val_fn: 14.0000 - val_accuracy: 0.9996 - val_precision: 0.8983 - val_recall: 0.7910 - val_auc: 0.9326 - val_prc: 0.8267\n",
            "Epoch 9/10\n",
            "2849/2849 [==============================] - 34s 12ms/step - loss: 0.0036 - tp: 208.0000 - fp: 29.0000 - tn: 181933.0000 - fn: 106.0000 - accuracy: 0.9993 - precision: 0.8776 - recall: 0.6624 - auc: 0.9339 - prc: 0.7555 - val_loss: 0.0023 - val_tp: 50.0000 - val_fp: 3.0000 - val_tn: 45499.0000 - val_fn: 17.0000 - val_accuracy: 0.9996 - val_precision: 0.9434 - val_recall: 0.7463 - val_auc: 0.9326 - val_prc: 0.8326\n",
            "Epoch 10/10\n",
            "2849/2849 [==============================] - 27s 9ms/step - loss: 0.0039 - tp: 191.0000 - fp: 36.0000 - tn: 181926.0000 - fn: 123.0000 - accuracy: 0.9991 - precision: 0.8414 - recall: 0.6083 - auc: 0.9418 - prc: 0.7210 - val_loss: 0.0023 - val_tp: 52.0000 - val_fp: 4.0000 - val_tn: 45498.0000 - val_fn: 15.0000 - val_accuracy: 0.9996 - val_precision: 0.9286 - val_recall: 0.7761 - val_auc: 0.9326 - val_prc: 0.8329\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ad7279990>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "METRICS = [\n",
        "      #keras.metrics.TruePositives(name='tp'),\n",
        "      #keras.metrics.FalsePositives(name='fp'),\n",
        "      #keras.metrics.TrueNegatives(name='tn'),\n",
        "      #keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]\n",
        "\n",
        "#def make_model(metrics=METRICS, output_bias=None):\n",
        "initial_bias = np.log([pos/neg])\n",
        "\n",
        "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(16, activation='relu',input_shape=(train_features.shape[-1],)))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias))\n",
        "model.summary()\n",
        "\n",
        "#model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss=keras.losses.BinaryCrossentropy(),metrics=metrics)\n",
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=METRICS)\n",
        "#Fit\n",
        "model.fit(\n",
        "  train_features,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_features, test_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NdPzxFgXbYHI"
      },
      "source": [
        "## Pruning\n",
        "\n",
        "We can also use pruning to improve our networks, which is built into Tensorflow and is similar in concept to the tree pruning we did earlier. \n",
        "\n",
        "### Pruning Results\n",
        "\n",
        "Pruning removes the least useful weights, increasing sparsity. These sparse models require less processing (since many calculations will be M * 0) and may be compressed down to take less space in memory. \n",
        "\n",
        "### Smaller Models\n",
        "\n",
        "One other consideration is that we can use pruning to create smaller models that are better able to be executed on weaker hardware. In the context of a full computer, creating a prediction with a neural network is pretty fast. If we want to move the model to small embedded devices though, the memory and processing needs can still be excessive. Some scenarios where this comes up are things like security cameras that can recognize images, robots that can navigate themselves, or evern small computers like a Raspberry Pi. For example, if you have a self driving small car, you may collect training data from the car's camera and sensors (throttle, steering, etc..), train a model that can produce a \"how to drive\" prediction on a computer, then export a condensed version of that model that can run on the car's smaller low powered processor to make the predictions as the car drives. This challenge is magnified if you are dealing with something like video, which can generate 30+ images per second. Small models that are almost as good, but can be run with less compouting power allow the power of neural networks to be expanded to more devices - train on a powerful computer, us on a small and weak computer.\n",
        "\n",
        "We can use the tflite set of tools to create special models that are optimized for lower computing power devices, though we won't explore that here. \n",
        "\n",
        "**Note:** pruning is largely a step that is for deployment of models, as we can make the processing more efficient and the memory required lesser. For us, it isn't the most critical of steps. In general, a smaller model that produces the same or similar accuracy is better, as you can do more with less. The reduction of overfitting and potential accuracy benefits are somewhat secondary to making the model more usable in practice. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FzYRlh3vtFH",
        "outputId": "3c0d4f0e-029d-4ae8-a0c9-4509b947f236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     || 237 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.21.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_model_optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrXm0AC9bYHI",
        "outputId": "72e2ad31-aa4f-4760-d10c-615ce87eb5ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_dense_2  (None, 16)               946       \n",
            " 5 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_dropout  (None, 16)               1         \n",
            " _17 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_2  (None, 1)                35        \n",
            " 6 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 982\n",
            "Trainable params: 497\n",
            "Non-trainable params: 485\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:218: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:225: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:238: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  trainable=False)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "model_for_pruning = prune_low_magnitude(model)\n",
        "\n",
        "\n",
        "model_for_pruning.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=METRICS)\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3sPhB8EbYHI",
        "outputId": "be02d7f7-896a-4d1b-8041-6f476ee62c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2849/2849 [==============================] - 37s 12ms/step - loss: 0.0070 - tp: 165.0000 - fp: 20.0000 - tn: 227444.0000 - fn: 216.0000 - accuracy: 0.9990 - precision: 0.8919 - recall: 0.4331 - auc: 0.7699 - prc: 0.5033 - val_loss: 0.0042 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 65.0000 - val_accuracy: 0.9986 - val_precision: 1.0000 - val_recall: 0.0299 - val_auc: 0.9178 - val_prc: 0.8041\n",
            "Epoch 2/10\n",
            "2849/2849 [==============================] - 31s 11ms/step - loss: 0.0065 - tp: 126.0000 - fp: 17.0000 - tn: 181945.0000 - fn: 188.0000 - accuracy: 0.9989 - precision: 0.8811 - recall: 0.4013 - auc: 0.7370 - prc: 0.4301 - val_loss: 0.0042 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 65.0000 - val_accuracy: 0.9986 - val_precision: 1.0000 - val_recall: 0.0299 - val_auc: 0.9326 - val_prc: 0.8188\n",
            "Epoch 3/10\n",
            "2849/2849 [==============================] - 31s 11ms/step - loss: 0.0064 - tp: 123.0000 - fp: 14.0000 - tn: 181948.0000 - fn: 191.0000 - accuracy: 0.9989 - precision: 0.8978 - recall: 0.3917 - auc: 0.8383 - prc: 0.4415 - val_loss: 0.0038 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 65.0000 - val_accuracy: 0.9986 - val_precision: 1.0000 - val_recall: 0.0299 - val_auc: 0.9325 - val_prc: 0.8255\n",
            "Epoch 4/10\n",
            "2849/2849 [==============================] - 32s 11ms/step - loss: 0.0060 - tp: 139.0000 - fp: 15.0000 - tn: 181947.0000 - fn: 175.0000 - accuracy: 0.9990 - precision: 0.9026 - recall: 0.4427 - auc: 0.9281 - prc: 0.4781 - val_loss: 0.0034 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 56.0000 - val_accuracy: 0.9988 - val_precision: 1.0000 - val_recall: 0.1642 - val_auc: 0.9474 - val_prc: 0.8312\n",
            "Epoch 5/10\n",
            "2849/2849 [==============================] - 31s 11ms/step - loss: 0.0059 - tp: 136.0000 - fp: 20.0000 - tn: 181942.0000 - fn: 178.0000 - accuracy: 0.9989 - precision: 0.8718 - recall: 0.4331 - auc: 0.9348 - prc: 0.4667 - val_loss: 0.0040 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 65.0000 - val_accuracy: 0.9986 - val_precision: 1.0000 - val_recall: 0.0299 - val_auc: 0.9473 - val_prc: 0.8275\n",
            "Epoch 6/10\n",
            "2849/2849 [==============================] - 31s 11ms/step - loss: 0.0063 - tp: 118.0000 - fp: 17.0000 - tn: 181945.0000 - fn: 196.0000 - accuracy: 0.9988 - precision: 0.8741 - recall: 0.3758 - auc: 0.9441 - prc: 0.4302 - val_loss: 0.0038 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 65.0000 - val_accuracy: 0.9986 - val_precision: 1.0000 - val_recall: 0.0299 - val_auc: 0.9473 - val_prc: 0.8323\n",
            "Epoch 7/10\n",
            "2849/2849 [==============================] - 33s 12ms/step - loss: 0.0059 - tp: 127.0000 - fp: 9.0000 - tn: 181953.0000 - fn: 187.0000 - accuracy: 0.9989 - precision: 0.9338 - recall: 0.4045 - auc: 0.9480 - prc: 0.4596 - val_loss: 0.0030 - val_tp: 24.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 43.0000 - val_accuracy: 0.9991 - val_precision: 1.0000 - val_recall: 0.3582 - val_auc: 0.9474 - val_prc: 0.8347\n",
            "Epoch 8/10\n",
            "2849/2849 [==============================] - ETA: 0s - loss: 0.0060 - tp: 123.0000 - fp: 18.0000 - tn: 181944.0000 - fn: 191.0000 - accuracy: 0.9989 - precision: 0.8723 - recall: 0.3917 - auc: 0.9417 - prc: 0.4512"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep()\n",
        "]\n",
        "\n",
        "model_for_pruning.fit(train_features, train_labels,\n",
        "                  batch_size=64, epochs=10, validation_split=.2,\n",
        "                  callbacks=callbacks)\n",
        "model_for_pruning.evaluate(test_features, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise\n",
        "\n",
        "Predict the price of diamonds! \n",
        "\n",
        "![Diamonds](images/diamonds.jpeg \"Diamonds\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>price</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>cut_Ideal</th>\n",
              "      <th>cut_Premium</th>\n",
              "      <th>cut_Very Good</th>\n",
              "      <th>...</th>\n",
              "      <th>color_I</th>\n",
              "      <th>color_J</th>\n",
              "      <th>clarity_IF</th>\n",
              "      <th>clarity_VVS1</th>\n",
              "      <th>clarity_VVS2</th>\n",
              "      <th>clarity_VS1</th>\n",
              "      <th>clarity_VS2</th>\n",
              "      <th>clarity_SI1</th>\n",
              "      <th>clarity_SI2</th>\n",
              "      <th>clarity_I1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.23</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.23</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>327</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.29</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>334</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.31</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>335</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   carat  depth  table  price     x     y     z  cut_Ideal  cut_Premium  \\\n",
              "0   0.23   61.5   55.0    326  3.95  3.98  2.43          1            0   \n",
              "1   0.21   59.8   61.0    326  3.89  3.84  2.31          0            1   \n",
              "2   0.23   56.9   65.0    327  4.05  4.07  2.31          0            0   \n",
              "3   0.29   62.4   58.0    334  4.20  4.23  2.63          0            1   \n",
              "4   0.31   63.3   58.0    335  4.34  4.35  2.75          0            0   \n",
              "\n",
              "   cut_Very Good  ...  color_I  color_J  clarity_IF  clarity_VVS1  \\\n",
              "0              0  ...        0        0           0             0   \n",
              "1              0  ...        0        0           0             0   \n",
              "2              0  ...        0        0           0             0   \n",
              "3              0  ...        1        0           0             0   \n",
              "4              0  ...        0        1           0             0   \n",
              "\n",
              "   clarity_VVS2  clarity_VS1  clarity_VS2  clarity_SI1  clarity_SI2  \\\n",
              "0             0            0            0            0            1   \n",
              "1             0            0            0            1            0   \n",
              "2             0            1            0            0            0   \n",
              "3             0            0            1            0            0   \n",
              "4             0            0            0            0            1   \n",
              "\n",
              "   clarity_I1  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex_df = sns.load_dataset(\"diamonds\")\n",
        "ex_df = pd.get_dummies(ex_df)\n",
        "ex_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = ex_df[\"price\"]\n",
        "X = ex_df.drop(columns={\"price\"})\n",
        "X_tr_ex, X_te_ex, y_tr_ex, y_te_ex = train_test_split(X, y)\n",
        "start_width = X.shape[1]\n",
        "start_width"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Generate a Baseline\n",
        "\n",
        "I'll use a different loss - mean absolute percentage. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "422/422 [==============================] - 1s 1ms/step - loss: 9.6126\n",
            "9.612637519836426\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnXElEQVR4nO3deXxU9dn38c81SzLZ2cMSlEUqCigIWK0WQbRYsS7VKi5IXWtt1fK03OpjH/W2tVptq+2ttVWr4i0KuFRpbXFBImIVAUURUUBECCAhQCAJSWb7PX9kpChQyXoyZ77v12teM+fMmTPXJfg9h9+cxZxziIiIvwS8LkBERFqewl1ExIcU7iIiPqRwFxHxIYW7iIgPhbwuAKBLly6uT58+Tf58TU0NeXl5LVdQGsjEniEz+1bPmaOxfS9evLjCOdd1b++1i3Dv06cPixYtavLnS0tLGT16dMsVlAYysWfIzL7Vc+ZobN9m9um+3tOwjIiIDyncRUR8SOEuIuJDXznmbmYPAacA5c65wal5nYAZQB9gDXC2c25b6r3rgUuABHC1c+6FVqlcRNJeLBajrKyMurq6L8wvKipi+fLlHlXlnX31HYlEKCkpIRwO7/e69ucH1UeAe4BHd5t3HTDHOXe7mV2Xmr7WzA4FJgCDgJ7Ay2b2NedcYr8rEpGMUVZWRkFBAX369MHMds2vqqqioKDAw8q8sbe+nXNs2bKFsrIy+vbtu9/r+sphGefcPGDrl2afBkxNvZ4KnL7b/OnOuXrn3CfAKuDI/a5GRDJKXV0dnTt3/kKwyxeZGZ07d97jXzdfpamHQhY75zYCOOc2mlm31PxewJu7LVeWmrcHM7scuByguLiY0tLSJpYC1dXVzfp8OsrEniEz+/Zzz0VFRVRXV+8xP5FIUFVV5UFF3vpPfdfV1TXq70FLH+e+t83vXq8p7Jy7H7gfYMSIEa4px7Sur6zliQVrOTCwnlMy7JhYHQecOfzc8/Lly/c6/KJhmT1FIhGGDRu23+tq6tEym8ysB0DquTw1vwzovdtyJcCGJn7HV6qqi3HP3FWsqky21leIiM/l5+d7XUKraGq4zwImpV5PAp7bbf4EM8s2s77AAOCt5pW4b/275pMVDLCuSuEuIrK7rwx3M3sCeAM42MzKzOwS4HbgRDNbCZyYmsY5twyYCXwAzAZ+1JpHyoSDAQ7qlq9wF5Fmc84xZcoUBg8ezJAhQ5gxYwYAGzduZNSoUQwdOpTBgwfz2muvkUgk+P73v79r2bvuusvj6vf0lWPuzrlz9/HW2H0sfytwa3OKaoxDehQyZ1nm/fAi4jf//bdlfLBhB9Dww2IwGGz2Og/tWchN3xm0X8s+88wzLFmyhHfffZeKigpGjhzJqFGjePzxxxk3bhw33HADiUSCnTt3smTJEtavX8/7778PQGVlZbNrbWnpfYZq1SbOSMwmUl/Blup6r6sRkTQ2f/58zj33XILBIMXFxRx33HEsXLiQkSNH8vDDD3PzzTezdOlSCgoK6NevH6tXr+aqq65i9uzZFBYWel3+HtrFVSGbrGojx370Kw4LTGb5xiqOHZDtdUUi0kS772F7cbSMc3s9sI9Ro0Yxb948nn/+eSZOnMiUKVO48MILeffdd3nhhRe49957mTlzJg899FCb1vtV0nvPvajhwJyetoUPP9vhcTEiks5GjRrFjBkzSCQSbN68mXnz5nHkkUfy6aef0q1bNy677DIuueQS3n77bSoqKkgmk5x55pn84he/4O233/a6/D2k9557bicI5dDPVbBko8JdRJrujDPO4I033uDwww/HzLjjjjvo3r07U6dO5c477yQcDpOfn8+jjz7K+vXrueiii0gmGw7muO222zyufk/pHe5mUFRCv8otPLFRP6qKSON9foasmXHnnXdy5513fuH9SZMmMWnSpD0+1x731neX3sMyAEUl9ApsYVV5FdG4DokUEQGfhHvXZAWxhGN1xZ7XqBARyUTpH+4dDiA/UUkWMZZr3F1EBPBDuBeVANA7tI3lGncXEQF8FO5HdtqpPXcRkRTfhPvhBVXacxcRSUn/cC9suBfIgOxKKqrr2VylyxCIiKR/uIeyqc/qSElgC4CGZkSk1fyna7+vWbOGwYMHt2E1/1n6hztQn92FjrFNAHy6pcbjakREvJfeZ6im1EW6UlC9gVDA2Li9cTeRFZF24p/XwWdLAchJxCHYAvHUfQh8+/Z9vn3ttddy4IEHcuWVVwJw8803Y2bMmzePbdu2EYvF+OUvf8lpp53WqK+tq6vjhz/8IYsWLSIUCvG73/2OMWPGsGzZMi666CKi0SjJZJKnn36anj17cvbZZ1NWVkYsFuOmm27inHPOaVbb4JNwr8/uin32Dt3ys/hsh8JdRPbPhAkT+MlPfrIr3GfOnMns2bOZPHkyhYWFVFRUcNRRR3HqqaditrdbRO/dvffeC8DSpUv58MMP+da3vsWKFSv405/+xDXXXMP5559PNBolkUjwj3/8g549e/L8889TVVW163o1zeWLcK+LdIV4LQO6RNmkcBdJT7vtYde20SV/hw0bRnl5ORs2bGDz5s107NiRHj16MHnyZObNm0cgEGD9+vVs2rSJ7t277/d658+fz1VXXQXAwIEDOfDAA1mxYgVHH300t956K2VlZXz3u99lwIABDBkyhJ/97Gdce+21HH/88YwbN65FevPJmHtXAAbmbNewjIg0yllnncVTTz3FjBkzmDBhAtOmTWPz5s0sXryYJUuWUFxcTF1d43JlX9eGP++885g1axY5OTmMGzeOV155ha997WssXryYIUOGcPPNN3PLLbe0RFs+2nMH+mZtY9P2jh5XIyLpZMKECVx22WVUVFTw6quvMnPmTLp160Y4HGbu3Ll8+umnjV7nqFGjmDZtGscffzwrVqxg7dq1HHzwwaxevZp+/fpx9dVXs3r1at577z0GDhxIp06duOCCCwgGg7vu3dpcvgj3z/fcewe2UhM9kKq6GAWRsMdViUg6GDRoEFVVVfTq1YsePXpw/vnn853vfIcRI0YwdOhQBg4c2Oh1XnnllVxxxRUMGTKEUCjEI488QnZ2NjNmzOCxxx4jHA7TvXt3brzxRhYuXMiUKVMIBAIEAgHuv//+FunLF+EeCxdAKIfiZDkAn22vU7iLyH5bunTprtddunThjTfe2Otyn1/7fW/69Omz64bZkUiERx55ZI9lrr/+eq6//vovzBs3btyucfaWvL2gL8bcP79pR8d4Ktz1o6qIZDhf7LkDUFRCfs1nQMOeu4hIa1i6dCkTJ078wrzs7GwWLFjgUUV756twz9r0AaBwF0knzrlGHUPutSFDhrBkyZI2/c59HX3zn/hjWAagqDdWs4luORqWEUkXkUiELVu2NCm8MoVzji1bthCJRBr1Of/suXfoDcDgghqdyCSSJkpKSigrK2Pz5s1fmF9XV9foMPODffUdiUQoKSlp1Lr8E+6p67ofnFPJPA3LiKSFcDhM375995hfWlrKsGHDPKjIWy3Zt4+GZRrCvX94i/bcRSTj+Sjce4MF6G0VVFRHicZb5uI7IiLpyD/hHgxDUQnFiY0A2nsXkYzmn3AH6NiHjtENgMJdRDKb78I9r2YdoMMhRSSz+S7cQ7UV5FKnE5lEJKP5LNwbDqk6KFyhcBeRjOazcO8DwGF5lRqWEZGM1qxwN7PJZrbMzN43syfMLGJmnczsJTNbmXpuu7tnpML9a1mbtecuIhmtyeFuZr2Aq4ERzrnBQBCYAFwHzHHODQDmpKbbRk5HyC6ib2Cz9txFJKM1d1gmBOSYWQjIBTYApwFTU+9PBU5v5nfsPzPo1IeebhPlO+pJJnUxIhHJTNacq7GZ2TXArUAt8KJz7nwzq3TOddhtmW3OuT2GZszscuBygOLi4uHTp09vch3V1dXk5+cDcOiyX2OVaxhZ9Rv+MCaXwuz0uZRoY+zecybJxL7Vc+ZobN9jxoxZ7Jwbsbf3mnzhsNRY+mlAX6ASeNLMLtjfzzvn7gfuBxgxYoQbPXp0U0uhtLSUXZ+PvULyjYUYSfoNPoLBvYqavN727As9Z5BM7Fs9Z46W7Ls5wzInAJ845zY752LAM8A3gE1m1gMg9Vze/DIboWMfAskY3dmms1RFJGM1J9zXAkeZWa413EZlLLAcmAVMSi0zCXiueSU2UuqImQOsnA2VtW361SIi7UWTw905twB4CngbWJpa1/3A7cCJZrYSODE13XZSJzIdmrOFd9ZWtulXi4i0F826WYdz7ibgpi/NrqdhL94bRSVgQb7esYobV1Wk3f0ZRURagr/OUIVdl/49JHsL5VX1rCyv9roiEZE2579wB+jYhx7JzwCYv7LC42JERNqeP8O9U1+ydqylX5c85q9SuItI5vFnuHfsAzsrGNM3hzdXbyGW0C33RCSz+DfcgTHFteyMJliyrtLTckRE2pqvw31YQSUBg9c07i4iGcaf4d6pH1iQvFXPc1hJB17XuLuIZBh/hnukCEZNgaUzubRoEUvWVVJVF/O6KhGRNuPPcIeGcO99FCd9egc93We8uXqr1xWJiLQZ/4Z7MARnPkAwEODe7D9y4zPvsHCNAl5EMoN/wx2gwwHYqX/gMFby5+TN/M8DD/DQa6tpzjXsRUTSgb/DHWDQGXDK3QzO3caj4V9xxEtncffv76D0g/W6U5OI+Jb/wx1gxEUEfvIeyfF30z+vnsmVv+KQGd/gsduvYNb8t6mPJ7yuUESkRWVGuAOEsgmMvIiCKe8RO+cJXPEQLojOYNxLJ/L3X01g2uzXdESNiPhGsy75m5YCQcKHnEz3Q07GbfmYrf/4Nad9/DS88TLPvTmG6HE3cOY3h5EVypztnoj4T0YnmHXuT4+J9xOa/B7bBk3iNEoZX3oKf7pjCi8tLfO6PBGRJsvocN+lqBddz76b4JX/It5jGFdHH6T7k+P5xaN/Y/tODdWISPpRuO/Gug2k0w+eJ37mIwzI2srkjy/j9t/dxqsrNntdmohIoyjcv8yM0JAziPz4XwSKD+G2+G9Z/eiPePDVlTo+XkTShsJ9Xzr0JvfyF4iP/AEXhV6g28tX8f/+ukTXhheRtKBw/09CWYTG30Fy7M2cGnyD0e9M5oqHX6cupuPiRaR9U7jvh8A3J8P43zI2uISL1l7LT6Yt0B68iLRrCvf9NfJS7PT7ODawjBM+vo0pM5fo8gUi0m4p3Btj6Lkw+nrOCs6j+/t/5sZZ7+tHVhFplxTujXXctTD4LK4LT2fzW08xY+E6rysSEdmDwr2xzOC0e3G9RvKH7Pt4aNbLLN+4w+uqRES+QOHeFOEIds6jhLMi3Bn+E1dNW0hNfdzrqkREdlG4N1VhTwLjf8Ph7iPGVj7Jz5/V+LuItB8K9+YY8j045DtMCT/F+0sW8OIHm7yuSEQEULg3jxmMv4tgTiH35t7PrbOWsjOq4RkR8Z7Cvbnyu2Ljf8vXEqs4tvqf3PPKKq8rEhFRuLeIQ0+HA47mushfefy1Zawqr/a6IhHJcAr3lmAG3/olhYmtXBF+npt0cpOIeEzh3lJKRsCgM7gk+DwrV61izvJyrysSkQymcG9JY28i5BLcmPdX7p6zQnvvIuKZZoW7mXUws6fM7EMzW25mR5tZJzN7ycxWpp47tlSx7V6nvtiRlzE+8Qq1G5bzkg6NFBGPNHfP/ffAbOfcQOBwYDlwHTDHOTcAmJOazhzf/CmEsvlp3mzuenmlrhwpIp5ocribWSEwCvgLgHMu6pyrBE4DpqYWmwqc3rwS00xeF+yIiZyUeJXKjZ/w4gefeV2RiGQga+q4sJkNBe4HPqBhr30xcA2w3jnXYbfltjnn9hiaMbPLgcsBiouLh0+fPr1JdQBUV1eTn5/f5M+3tEjtJo5ccAUzOIl7QxO55ZgcAmYt+h3tree2kol9q+fM0di+x4wZs9g5N2KvbzrnmvQARgBx4Oup6d8DvwAqv7Tctq9a1/Dhw11zzJ07t1mfbxVPX+ZitxS7w66d7l54f2OLr75d9twGMrFv9Zw5Gts3sMjtI1ebM+ZeBpQ55xakpp8CjgA2mVkPgNRzZh4TeMw1hBK1/CjvFR5+fY3X1YhIhmlyuDvnPgPWmdnBqVljaRiimQVMSs2bBDzXrArTVfEgGDCOiYHZvLN6g675LiJtqrlHy1wFTDOz94ChwK+A24ETzWwlcGJqOjMd+xNyYpV8L+tfTP3XGq+rEZEMEmrOh51zS2gYe/+ysc1Zr28ccDR0O5QfVM1j7Dtj+a+TBtIpL8vrqkQkA+gM1dZkBiMupqT2I76WWMUTb631uiIRyRAK99Z22NkQzuX/dHqdx978lFgi6XVFIpIBFO6tLVIEg89kVF0p1du36pIEItImFO5tYcTFBBO1TMpfwMxF67yuRkQygMK9LfQ6AnoczqSsucxbUc7G7bVeVyQiPqdwbysjLqbrzlUMZSVPLy7zuhoR8TmFe1sZfBaEc7my41vMXFSmq0WKSKtSuLeV7Hw45FSOi77Gpq2VLPhkq9cViYiPKdzb0tBzCcer+E5kCU/qh1URaUUK97bU55tQ2ItLC97iH+9vZEddzOuKRMSnFO5tKRCEw87m4OoF5Me28fd3N3pdkYj4lMK9rR1+LuYSXFy0kGffWe91NSLiUwr3ttb1YOh5BN8LzeetNVsp27bT64pExIcU7l44/Fy61qxgoK1l1rsbvK5GRHxI4e6FwWdCIMQVHRfx3DsKdxFpeQp3L+R1hv5jOTE5nxWbtusuTSLS4hTuXhlyFnl1n3FkcCXPLtEPqyLSshTuXjn4ZAjl8INOb/O3JRt0OQIRaVEKd69k58PB3+aY+vmUb6/mrTW6HIGItByFu5eGnEV2dBvHZy3nuSX6YVVEWo7C3UsHnQCRIi7tsJh/vr9Rt+ATkRajcPdSKBsO+Q5H7Hyd2p01zF9Z4XVFIuITCnevDfkeoXgNp0Te4286oUlEWojC3Wt9vgn5xXy/cDEvLPuMuljC64pExAcU7l4LBGHQGQyqfoNAtIq5H5Z7XZGI+IDCvT0YfBaBZJTv5i7RtWZEpEUo3NuDkhHQ4QAm5i/klQ/LqdJNPESkmRTu7YEZDD6T/lWLyItX8tIHm7yuSETSnMK9vRh8FuYSnJf/tk5oEpFmU7i3F8WDoOtAzslZwPxVFVRU13tdkYikMYV7e2EGg8+id9W7FCc384+lur+qiDSdwr09GfxdAC7u8I7uryoizaJwb08694deIzg9+Dpvr61k7RbdX1VEmkbh3t4cdg5dalZwsK1l1rvaexeRplG4tzeDvwuBEFd2WsSzSzbgnG7iISKN1+xwN7Ogmb1jZn9PTXcys5fMbGXquWPzy8wgeV3goBM4IT6P1eU7+ED3VxWRJmiJPfdrgOW7TV8HzHHODQDmpKalMQ47h7z6co4J6iYeItI0zQp3MysBxgMP7jb7NGBq6vVU4PTmfEdGOvjbkF3IFR0X8ew764nrJh4i0kjWnDFdM3sKuA0oAH7mnDvFzCqdcx12W2abc26PoRkzuxy4HKC4uHj49OnTm1xHdXU1+fn5Tf58e3Twh/9D5/L5HLbzPq4cXshhXUNfeN+PPe+PTOxbPWeOxvY9ZsyYxc65EXt7L7S3mfvDzE4Byp1zi81sdGM/75y7H7gfYMSIEW706EavYpfS0lKa8/l26cAgTH2ZM3KW8FHsdK4efcQX3vZlz/shE/tWz5mjJftucrgDxwCnmtnJQAQoNLPHgE1m1sM5t9HMegC6QHlTHHgMFJZwCW9y8rKj2b4zRlFu2OuqRCRNNHnM3Tl3vXOuxDnXB5gAvOKcuwCYBUxKLTYJeK7ZVWaiQACGnkf/HW/RObGZv72nH1ZFZP+1xnHutwMnmtlK4MTUtDTF0PMwHD/s8CZPLS7zuhoRSSMtEu7OuVLn3Cmp11ucc2OdcwNSz1tb4jsyUqe+0HcUp1PKu+u2sqq8yuuKRCRN6AzV9m7YhRTWreeY4HKe1N67iOwnhXt7d8gpECnixx3e5OnF64nGdcy7iHw1hXt7F86BId9jZO1rRKu36BZ8IrJfFO7pYNhEgskoF+Yv4vG3PvW6GhFJAwr3dNBzKHQfwqTsUl5fVcHqzdVeVyQi7ZzCPV2MuISuNSs4MriSJ95a63U1ItLOKdzTxWFnQ3YRUzrO46nFZUQTus67iOybwj1dZOXBsPMZvvM1Qjs3s2hTwuuKRKQdU7ink5GXEkjGuKLgNV5ZG/O6GhFpxxTu6aRzf+h/PBMCc1hTGeWdtdu8rkhE2imFe7o58nLy6ssZH17Mg6994nU1ItJOKdzTzYBvQdEB/DjnRf75/kbWbd3pdUUi0g4p3NNNIAhHXcGA6HKGB1by0OvaexeRPSnc09ERk4iFCrix44vMXLiO7bX6cVVEvkjhno6y81nfazxDql+nZ+xTpuukJhH5EoV7miorGQ/hXP5fhxf5y/xPqIvpuHcR+TeFe5qKhwth+Pc5tq6UcFUZj72pC4qJyL8p3NPZ0T8mYMaNnedwX+nH1NTHva5IRNoJhXs6K+oFh0/gxLrZZNds4JF/rfG6IhFpJxTu6W70dQQw7uz8N/786sc6ckZEAIV7+isqgaN+yDdqXqakfhV/ma/j3kVE4e4Px07Gcjrwmw7P8OBrq/lse53XFYmIxxTufpDTAUZN4dDaRRzllvCL5z/wuiIR8ZjC3S9GXgodDuDXhU8x+70y5q3Y7HVFIuIhhbtfhLLhW7fStWYl1xa8yE2zllEf14lNIplK4e4nh54Kh5zKpYkZ2JaVPDBvtdcViYhHFO5+c/JvCGTl8kDRI9zzygpWbKryuiIR8YDC3W8KiuGk2+lf9z4Xh1/m6ife0XVnRDKQwt2PDp8AB53ATwNPENv0IXfM/sjrikSkjSnc/cgMTr2HYHYejxf9kSdeX07pR+VeVyUibUjh7leFPeDMB+hWt4a7C6bxsyffY9MOndwkkikU7n7W/3jsuP9iXGwO46IvccVji3V4pEiGULj73XHXQt9R3BJ6mMS6xdz47DKcc15XJSKtTOHud4EgnPkQwYJiHs+/m3mLlvDYAt2WT8TvFO6ZIL8rnDeDPIsyo+Bu7py1WJcnEPE5hXumKD4UO/sResfX8EDeH/nRY2+xZF2l11WJSCtpcribWW8zm2tmy81smZldk5rfycxeMrOVqeeOLVeuNMtBJ2An38HXYwu5I3w/Fz/0Jh9vrva6KhFpBc3Zc48DP3XOHQIcBfzIzA4FrgPmOOcGAHNS09JejLwUxtzAtxOl/F/+woUPLmB9Za3XVYlICws19YPOuY3AxtTrKjNbDvQCTgNGpxabCpQC1zarSmlZo6ZAtIazXr+bnfVhzr4Pnrj8aA7onOt1ZSLSQqwlDoszsz7APGAwsNY512G397Y55/YYmjGzy4HLAYqLi4dPnz69yd9fXV1Nfn5+kz+fjprds3MctOoBStY/z6PJb3OXTeTaI3Ponte+f4bRn3VmyMSeofF9jxkzZrFzbsRe33TONesB5AOLge+mpiu/9P62r1rH8OHDXXPMnTu3WZ9PRy3ScyLh3D+ude6mQvfMzWe4kbfMdh9s2N789bYi/Vlnhkzs2bnG9w0scvvI1SYPywCYWRh4GpjmnHsmNXuTmfVwzm00sx6ALmrSXgUCcNJtkJ3PGfPuJM/Vc96f4twz8escc1AXr6sTkWZoztEyBvwFWO6c+91ub80CJqVeTwKea3p50urM4Pifwwk3863kfB4M38GPHirlmbfLvK5MRJqhOQOsxwATgePNbEnqcTJwO3Cima0ETkxNS3t37GQ49R6OSL7Pc7m/5Ncz5/LbFz8imdSlCkTSUXOOlpkP2D7eHtvU9YqHjpiIFfbkgJkX8kL+f3Pe3Mks37iDu84ZSkEk7HV1ItII7fvQCGl7B43FLp5NUW4Ws3JuoWDls5x+7+usKtft+kTSicJd9tR9CHZ5KaHew7krdA8XVT/AqX94lf99Y42uKCmSJhTusnf53eDC5+DIH3CB+zt/y72FR2e9wCVTF1FepZt+iLR3CnfZt2AYTr4DvvcI/UIVzI7cwKCPH+TE37zCfaUf68bbIu2Ywl2+2qAzsCsXEDxkPD8NTuefWdey+MVpnPi7Uv76ThmxRNLrCkXkSxTusn/yu8LZU2HC4/QszObBrN9yX/TnPPnkNI779Ss8+NpqdtTFvK5SRFKadYaqZKCB42HAOHjnUQaV3s7jiV+xLnkAf549ljEvjmLU4H6cNbyEo/t1JhDY15GyItLaFO7SeMEQjLgYO/w8WPYMvRf8mV9ufJibbBqvLT+Mme8eyc9zj+KoQ/tx4qHd+Eb/LkTCQa+rFskoCndpunAEhp4Hh58L698mvPRJxnzwLMdX/ZFE/E8sfbc/r749mKl2KPQ8gsMPOoAj+3RiSEkRRTk6KUqkNSncpfnMoGQ4lAzHxv0KyhYSXPUSh308l8M3PIe5v5LcZKza2JOl8/ryerKEqoJ+RHoeQudeA+jXvSMHdcund8dcskL6GUikJSjcpWUFAnDA1+GArxM4/udQWwnrFxEoW0zfdQs5cMN7ZNfOhzpgNcQ/DrDedeFTV8wiulAV6U6ioBfBol5EOvWmoNsBdOnUieKiHLoXRbzuTiRtKNyldeV0gINOgINOYNdATN12qFgJFStJlq+k8LOVDN66muE175IXmwtbaXh8klrchdlCIZ+4AoIU8uJrHanP7kQiuyMupwPB3E6E8jqRnd+BnIJO5BZ2IK+gA4WFRRTlZpMdCtBwEVORzKFwl7YXKYKSEVAygiwga/f3YnWwYz1UbSS6rYyq8nXUbf+MeNVmCmu2kL9jI4VWTl5tJZGddbBt31+TdEY1OVSQS43lUx/IJRrMJRbKJx7Ow4XzcFl5WFYegaxcAtn5hCINj3BuIVk5+WTn5BHJySMnN59IfiFZ2XlYQENH0v4p3KV9CUegc3/o3J+sPtD5S2+XlpYyevTohol4PdRW4nZuYWfVVmq2b6N2RwXRnTuI7dxBom4Hrm4HVr+DYP12IvEaChLbyYpuJFJXS8TVkuPqCNj+Xy8n6Yxasqi1CFHLJmoREoEwiUAWyUAW8WCEZCCbZCiCC2VDMBsLZUMogoUjEM4hGM4mGMommJXd8Dorl2BWhFBWhFBWNuGsCFmp51BWhOy6CqipaDhjOJjV8Ajo6CP5zxTukr5C2VBQjBUUk1cMeU1Zh3Mk62uo3VlFbc0OamuqiNZWN2wg6qqJ1e8kXreTZH0NLroTotVYrAaL12HxOoLxWgLJKIFEPcFYlHB0CxFXT7arJ+xihImRnXqErGln8h4N8OYX5yUIECdM3EIkUo+4ZTVsaCwLFwiRDIRwFsIFs0gGwhAI44JZEAilNhJhLPUgmIWFwlgom0AwCwuGCITCBENZBIIhgqEwgWCIQDBMMBxueC+YRSicRSAUblhnINyw0QmEGjZEFkxNB//9fjD1CHz+mWDDD/LS4hTuktnMCETyyYvkk9epR4uvPpl01MeTVMcT1Eej1NfWEI3WU19XS7S+jni0jni0lkR0J4lYlESsnmS0jmQiSjJaj4vXs2XzJjoW5ePi9ZCIQiJKIBGFRAxL/vsRTEYJpZ4DLk7QxQm4KCFXQ4g4WQ2bA0IkCFucMAlCqUcWcbLNmzOMEwRIWpAkQZIWwBFguDOq5odxBEgGgiStYUOVtBBJC+ICwYYNVyDYsBH5fF4g9O+Niu2+YQnu2viYNfwGY4FgwwYutTGyQAgCISwYxAKpRzBMIBAi8Pm8YIhAIIgFg7vmB4IhgsHgrs9jgd2+N/SlOkL/rgcals3KbzgDvIUp3EVaUSBg5GQFyckKQm4WdNj/O9t/7gtDUU2UTDqiiSTxpCMWTxJNJKmLJ4klGl7HE45oPEE8FiURjxGLR0lEoyQScRLxGPFYlGQiTjIeI5lIPVKvScQbnpMxXDyOS8ZwiQQuGYNkApINrwPJeGpDFIdknICLY8k45hK4ZAJzCQIuAS5JMh4llDQCLoHF4wRdgoBr2DCZSxIiTsPmIEbI6gg0bBoIkiTcsLkgSHLXc8gaNmJBEhjssXyIOMFGDM+1pGWdTmDQ1U+3+HoV7iIZIBAwIp/vLWZ7W8v++KoNmnOOeNKRSD3iCUfCOeLJ5K55iWTDMrGko86llkk2LPf5Z5Lu38smEkmSyTguESeZjJNMJFIbssSueS6ZaJj+/HUykdqQpeYlGuaTmjaXhNTG7PMNnbkYJJM453AuSZeSgxjUCv8NFe4iknbMjHDQ0FUt9k3HdImI+JDCXUTEhxTuIiI+pHAXEfEhhbuIiA8p3EVEfEjhLiLiQwp3EREfMue8OeX2C0WYbQY+bcYqugAVLVROusjEniEz+1bPmaOxfR/onNvrhWnaRbg3l5ktcs6N8LqOtpSJPUNm9q2eM0dL9q1hGRERH1K4i4j4kF/C/X6vC/BAJvYMmdm3es4cLda3L8bcRUTki/yy5y4iIrtRuIuI+FBah7uZnWRmH5nZKjO7zut6WoOZ9TazuWa23MyWmdk1qfmdzOwlM1uZeu7oda2twcyCZvaOmf09Ne3rvs2sg5k9ZWYfpv7Mj/Z7zwBmNjn19/t9M3vCzCJ+7NvMHjKzcjN7f7d5++zTzK5P5dtHZjauMd+VtuFuZkHgXuDbwKHAuWZ2qLdVtYo48FPn3CHAUcCPUn1eB8xxzg0A5qSm/egaYPlu037v+/fAbOfcQOBwGnr3dc9m1gu4GhjhnBsMBIEJ+LPvR4CTvjRvr32m/j+fAAxKfeaPqdzbL2kb7sCRwCrn3GrnXBSYDpzmcU0tzjm30Tn3dup1FQ3/s/eiodepqcWmAqd7UmArMrMSYDzw4G6zfdu3mRUCo4C/ADjnos65Snzc825CQI6ZhYBcYAM+7Ns5Nw/Y+qXZ++rzNGC6c67eOfcJsIqG3Nsv6RzuvYB1u02Xpeb5lpn1AYYBC4Bi59xGaNgAAN08LK213A38F5DcbZ6f++4HbAYeTg1FPWhmefi7Z5xz64HfAGuBjcB259yL+Lzv3eyrz2ZlXDqHu+1lnm+P6zSzfOBp4CfOuR1e19PazOwUoNw5t9jrWtpQCDgCuM85NwyowR9DEf9Raoz5NKAv0BPIM7MLvK2qXWhWxqVzuJcBvXebLqHhn3K+Y2ZhGoJ9mnPumdTsTWbWI/V+D6Dcq/payTHAqWa2hoYht+PN7DH83XcZUOacW5CafoqGsPdzzwAnAJ845zY752LAM8A38H/fn9tXn83KuHQO94XAADPra2ZZNPzwMMvjmlqcmRkNY7DLnXO/2+2tWcCk1OtJwHNtXVtrcs5d75wrcc71oeHP9hXn3AX4uG/n3GfAOjM7ODVrLPABPu45ZS1wlJnlpv6+j6XhtyW/9/25ffU5C5hgZtlm1hcYALy132t1zqXtAzgZWAF8DNzgdT2t1OOxNPxT7D1gSepxMtCZhl/WV6aeO3ldayv+NxgN/D312td9A0OBRak/72eBjn7vOdX3fwMfAu8D/wtk+7Fv4AkafleI0bBnfsl/6hO4IZVvHwHfbsx36fIDIiI+lM7DMiIisg8KdxERH1K4i4j4kMJdRMSHFO4iIj6kcBcR8SGFu4iID/1//ovYP9QdKrUAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#baseline\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_tr_ex))\n",
        "\n",
        "mod_ex = keras.Sequential()\n",
        "mod_ex.add(normalizer)\n",
        "mod_ex.add(InputLayer(input_shape=(start_width,)))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(1))\n",
        "\n",
        "mod_ex.compile(optimizer='adam', loss=\"mean_absolute_percentage_error\")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20, restore_best_weights=True) \n",
        "\n",
        "hist_ex = mod_ex.fit(\n",
        "  X_tr_ex,\n",
        "  y_tr_ex,\n",
        "  epochs=100,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback],\n",
        "  verbose=0\n",
        ")\n",
        "print(mod_ex.evaluate(X_te_ex, y_te_ex))\n",
        "plot_loss(hist_ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Attempt Optimization\n",
        "\n",
        "Looks like lots of loss! What to do?\n",
        "\n",
        "Things to try:\n",
        "<ol>\n",
        "<li> Depth.\n",
        "<li> Width. \n",
        "<li> Activations. \n",
        "<li> Batches. \n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "422/422 [==============================] - 1s 1ms/step - loss: 6.9742\n",
            "6.9742231369018555\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAy7ElEQVR4nO3dd3xb5dn/8c8lWd4jju3Yzh5kQQwJDpCQkMUImzIbCjRQyigtq5Qfq4NuWp4CpQ8FylMgzJAyStgzg0CAxMFZZOIkTpzhETveS7p/f9zyUGzHI7Glk1zv10svSUfnHF0+kr86us99H4kxBqWUUs7jCnYBSimlukYDXCmlHEoDXCmlHEoDXCmlHEoDXCmlHCqsJ58sOTnZDB48uEvLVlRUEBMTc2gLOgRCtS4I3dq0rs4J1bogdGs73OrKysoqNMaktHjAGNNjl8zMTNNVCxYs6PKy3SlU6zImdGvTujonVOsyJnRrO9zqApabVjK13SYUEYkUka9FZKWIrBWR3/qn3y8ieSKS7b+c3emPFaWUUl3WkSaUGmCGMaZcRDzAEhF5z//Yw8aY/+m+8pRSSrWl3QD3776X++96/BcdvqmUUkEmpgND6UXEDWQBRwGPGWPuEpH7gauBUmA5cIcxpriVZa8HrgdITU3NnDt3bpcKLS8vJzY2tkvLdqdQrQtCtzatq3NCtS7oeG0iQkxMDG63uweqssf2RKRHnqsz2qvL6/VSUVHB/rk8ffr0LGPM+FZX2NEL0AtYAIwBUgE3tiviH4Gn21teD2L2rFCtTevqnFCty5iO15aTk2MKCgqMz+fr3oL8SktLe+R5OutAdfl8PlNQUGBycnJaPEZXD2LuF/YlwELgTGPMHmOM1xjjA54CTuzMupRSR47q6mqSkpJCcq84VIgISUlJVFdXd3iZjvRCSRGRXv7bUcBpwHoRSW8224XAms6Vq5Q6kmh4t6+z26gjvVDSgTn+dnAXMM8Y87aIPC8iY7EHNLcCN3Su1I77ZN0e3supZdq07noGpZRyno70QlkFjGtl+lXdUlErFm4o4IMtdWh/RaVUV8TGxlJeXt7+jA7jiHOhuAR8wS5CKaVCjDMC3CX4tOe5UuogGWO48847GTNmDBkZGbzyyisA7Nq1iylTpjB27FjGjBnDZ599htfr5eqrr26c9+GHHw5y9S316Mmsusolgv7ym1KHh9++tZZvd5Ye0nUe3Tee35x3TLvzvf7662RnZ7Ny5UoKCws54YQTmDJlCi+99BIzZ87kvvvuw+v1UllZSXZ2Nnl5eaxZY/tnlJSUHNKaDwVn7IFrE4pS6hBYsmQJl19+OW63m9TUVKZOncqyZcs44YQTeOaZZ7j//vtZvXo1cXFxDB06lJycHG6++Wbef/994uPjg11+C87YA3fpHrhSh4uO7Cl3F9NGkEyZMoXFixfzzjvvcNVVV3HnnXfywx/+kJUrV/LBBx/w2GOPMW/ePJ5++ukervjAHLIHrm3gSqmDN2XKFF555RW8Xi8FBQUsXryYE088kW3bttGnTx+uu+46rr32WlasWEFhYSE+n4+LL76Y3//+96xYsSLY5bfgiD1wt4iePUspddAuvPBCli5dynHHHYeI8Ne//pW0tDTmzJnDgw8+iMfjITY2lueee468vDyuueYafD7bgPvnP/85yNW35IgAdwnahKKU6rKGPuAiwoMPPsiDDz4Y8Pjs2bOZPXt2i+VCca+7OUc0oYh/D7yt9iullDoSOSLA3S57fgBtB1dKqSaOCHB/fuPVBFdKqUbOCPDGPXANcKWUauCMAPefYlHzWymlmjgkwO21VxNcKaUaOSTAtQlFKaX256gAN3pCFKVUDzjQDzVv3bqVMWPG9GA1bXNEgDd0I9QmFKWUauKYkZigTShKHRbeuxt2rz6060zLgLMeaPPhu+66i0GDBnHTTTcBcP/99yMiLF68mOLiYurq6vjDH/7ABRdc0Kmnra6u5ic/+QnLly8nLCyMhx56iOnTp7N27VquueYaamtr8fl8vPbaa/Tt25dLLrmE3bt34/V6+dWvfsX3v//9g/qzHRHgDT/06dN+4EqpLpg1axa33XZbY4DPmzeP999/n9tvv534+HgKCwuZMGEC559/fqd+WPixxx4DYPXq1axfv54zzjiDjRs38sQTT3DrrbdyxRVXUFtbi9fr5d133yU9PZ0PPvgAgH379h303+WIANeRmEodRg6wp9xdxo0bR35+Pjt37qSgoIDExETS09O5/fbbWbx4MS6Xi7y8PPbs2UNaWlqH17tkyRJuvvlmAEaNGsWgQYPYuHEjEydO5I9//CM7duzgoosuYvjw4WRkZHDHHXdw1113ce6553LKKacc9N/liDZwbUJRSh2sSy65hFdffZVXXnmFWbNm8eKLL1JQUEBWVhbZ2dmkpqZSXV3dqXW2dX6mH/zgB8yfP5+oqChmzpzJp59+yogRI1i0aBEZGRncc889/O53vzvov8kRe+ANvVB0KL1SqqtmzZrFddddR2FhIYsWLWLevHn06dMHj8fDggUL2LZtW6fXOWXKFF588UVmzJjBxo0byc3NZeTIkeTk5DB06FBuueUWcnJyWLVqFaNGjSI6Oporr7yS2NhYnn322YP+mxwV4LoDrpTqqmOOOYaysjL69etHeno6V1xxBeeddx7jx49n7NixjBo1qtPrvOmmm7jxxhvJyMggLCyMZ599loiICF555RVeeOEFPB4PaWlp/PrXv2bZsmXccccdhIWF4fF4ePzxxw/6b3JGgPsberQboVLqYKxe3dT7JTk5maVLl7Y6X8P5w1szePDgxh86joyMbHVP+p577uGee+4JmDZz5kxOPvlk4uLiulB56xzSBq4jMZVSan/O2ANvbELRAFdK9YzVq1dz1VVXBUyLiIjgq6++ClJFLTkiwBtHYupQeqUcyxjTqT7WwZaRkUF2dnaPPmdnd1LbbUIRkUgR+VpEVorIWhH5rX96bxH5SEQ2+a8Tu1hz+0VqN0KlHC0yMpKioiL9Fn0AxhiKioqIjIzs8DId2QOvAWYYY8pFxAMsEZH3gIuAT4wxD4jI3cDdwF1dKbw9ot0IlXK0/v37s2PHDgoKCnrk+aqrqzsVhD2lvboiIyPp379/h9fXboAb+5HZcEjW478Y4AJgmn/6HGAh3RTgbu1GqJSjeTwehgwZ0mPPt3DhQsaNG9djz9dRh7ou6chXGhFxA1nAUcBjxpi7RKTEGNOr2TzFxpgWzSgicj1wPUBqamrm3LlzO11kdn49j6yo4dcTIxma4O708t2pvLz8gKeeDKZQrU3r6pxQrQtCt7bDra7p06dnGWPGt3jAGNPhC9ALWACMAUr2e6y4veUzMzNNVyxYv8cMuuttk7Vtb5eW704LFiwIdgltCtXatK7OCdW6jAnd2g63uoDlppVM7VQ/cGNMCbap5Exgj4ikA/iv8zv9sdJB2o1QKaVa6kgvlBQR6eW/HQWcBqwH5gOz/bPNBt7sphqbnQulu55BKaWcpyO9UNKBOf52cBcwzxjztogsBeaJyLVALnBpdxXZMJReuxEqpVSTjvRCWQW0OGxqjCkCTu2OovanQ+mVUqolR5wLpfEHHbQJRSmlGjkiwHUkplJKteSIAG8ciakBrpRSjRwR4G7tRqiUUi04IsAbD2JqG7hSSjVyRoDrL/IopVQLzghwbUJRSqkWHBXgOhJTKaWaOCLA3ToSUymlWnBEgIuOxFRKqRYcEeBuDXCllGrBEQGu3QiVUqolRwR4ww9ZazdCpZRq4ogAbziZlXYjVEqpJo4I8KbTyQa5EKWUCiHOCPCGkZia4Eop1cgZAa4jMZVSqgVHBbjugSulVBNHBLhb28CVUqoFRwS46FB6pZRqwREBriMxlVKqJUcEuHYjVEqplhwR4I0jMTXBlVKqkSMCXEdiKqVUS44IcG1CUUqplhwS4PZam1CUUqpJuwEuIgNEZIGIrBORtSJyq3/6/SKSJyLZ/svZ3VWkiCBoE4pSSjUX1oF56oE7jDErRCQOyBKRj/yPPWyM+Z/uK6+JS/R0skop1Vy7AW6M2QXs8t8uE5F1QL/uLmx/graBK6VUc9KZZgkRGQwsBsYAPweuBkqB5di99OJWlrkeuB4gNTU1c+7cuV0q9LoPyzl9UDiXjQzv0vLdpby8nNjY2GCX0apQrU3r6pxQrQtCt7bDra7p06dnGWPGt3jAGNOhCxALZAEX+e+nAm5sO/ofgafbW0dmZqbpqhH3vm3+8PbaLi/fXRYsWBDsEtoUqrVpXZ0TqnUZE7q1HW51ActNK5naoV4oIuIBXgNeNMa87g/+PcYYrzHGBzwFnNjpj5VO0CYUpZQK1JFeKAL8G1hnjHmo2fT0ZrNdCKw59OU1cYl2I1RKqeY60gtlEnAVsFpEsv3T7gUuF5GxgAG2Ajd0Q32NRLQboVJKNdeRXihLsC0Y+3v30JfTNhfahKKUUs05YiQm2ME82g9cKaWaOCbAXdqEopRSARwV4HoQUymlmjgmwLUboVJKBXJOgIv+pJpSSjXnmAB3Cfh0F1wppRo5JsC1CUUppQI5JsD1dLJKKRXIMQGuIzGVUiqQYwLcBfh8wa5CKaVCh2MCXEdiKqVUIMcEuI7EVEqpQM4JcHQkplJKNeeYALcDeYJdhVJKhQ7nBDg6ElMppZpzTIC7dCi9UkoFcEyAi2g3QqWUas4xAa4jMZVSKpBjAlzQboRKKdWcYwLcpb1QlFIqgGMCXES0H7hSSjXjmAB3oU0oSinVnGMCXPQgplJKBXBMgLu0G6FSSgVwTIDrSEyllArkmADXkZhKKRXIMQGuJ7NSSqlA7Qa4iAwQkQUisk5E1orIrf7pvUXkIxHZ5L9O7O5C9VfplVKqSUf2wOuBO4wxo4EJwE9F5GjgbuATY8xw4BP//W4j2oSilFIB2g1wY8wuY8wK/+0yYB3QD7gAmOOfbQ7wvW6qEdAmFKWU2p90ZnCMiAwGFgNjgFxjTK9mjxUbY1o0o4jI9cD1AKmpqZlz587tUqGPryhnc6mLv02L7tLy3aW8vJzY2Nhgl9GqUK1N6+qcUK0LQre2w62u6dOnZxljxrd4wBjToQsQC2QBF/nvl+z3eHF768jMzDRddeWj75uJf/q4y8t3lwULFgS7hDaFam1aV+eEal3GhG5th1tdwHLTSqZ2qBeKiHiA14AXjTGv+yfvEZF0/+PpQH6nP1Y6QUdiKqVUoI70QhHg38A6Y8xDzR6aD8z2354NvHnoy2viQtvAlVKqubAOzDMJuApYLSLZ/mn3Ag8A80TkWiAXuLRbKvQT0ZNZKaVUc+0GuDFmCXYke2tOPbTltM0l6OlklVKqGeeMxESbUJRSqjnHBLg9G6EmuFJKNXBMgOtITKWUCuScAEe0CUUppZpxTIC7tB+4UkoFcFSAazdCpZRq4pgAF+1GqJRSARwT4DoSUymlAjkmwMU/lEibUZRSynJMgLv8Aa7NKEopZTkmwBvG8mt+K6WU5ZgAb9gD18E8SillOSbARQNcKaUCOCbAXf5GFG1CUUopyzEBLnoQUymlAjgmwBsK1W6ESillOSbAdQ9cKaUCOSbAm3qhBLcOpZQKFY4LcG1CUUopyzEB3jCQR08pq5RSlnMCXJtQlFIqgGMCvLENXBNcKaUABwV407lQNMCVUgocFOAu0ZGYSinVnGMCXPuBK6VUIMcEuI7EVEqpQO0GuIg8LSL5IrKm2bT7RSRPRLL9l7O7t0zthaKUUvvryB74s8CZrUx/2Bgz1n9599CW1ZL+Io9SSgVqN8CNMYuBvT1QywHpDzoopVQg6UibsogMBt42xozx378fuBooBZYDdxhjittY9nrgeoDU1NTMuXPndqnQpbnlPPmt8JuJkQxJcHdpHd2hvLyc2NjYYJfRqlCtTevqnFCtC0K3tsOtrunTp2cZY8a3eMAY0+4FGAysaXY/FXBj9+D/CDzdkfVkZmaarnpk3kdm0F1vm29yi7u8ju6wYMGCYJfQplCtTevqnFCty5jQre1wqwtYblrJ1C71QjHG7DHGeI0xPuAp4MSurKczGgrVJhSllLK6FOAikt7s7oXAmrbmPVSkYSCPHsRUSikAwtqbQUReBqYBySKyA/gNME1ExgIG2Arc0H0lWno+cKWUCtRugBtjLm9l8r+7oZYDajydrCa4UkoBThqJqT/ooJRSARwX4LoDrpRSlmMCXH+RRymlAjkmwHUkplJKBXJMgIv+Io9SSgVwToD7rzW/lVLKckyAaxOKUkoFckyA60hMpZQK5JgAb7UbYV4WzL8ZfL6g1KSUUsHkjABf9m9OznkE2K8b4cYPYcVzUF0SlLKUUiqYnBHge3MYULIUMIEjMav3BV4rpdQRxBkBHtuHMF8tMVQHHsTUAFdKHcGcEeAxfQBIln14mzd3a4ArpY5gzgjwWBvgKZQE7oHXlNprDXCl1BHIUQGeLKWB3QgbDl5qgCuljkDOCPBmTSgB3Qi1CUUpdQRzRoBHJ2EQUmSfHsRUSik/ZwS4O4zasHiSaRbgPh9UN7SBlwStNKWUChZnBDhQE55AipQ0tYHXlmF/khPdA1dKHZEcE+C1nl62G2FDC0rz0NYAV0odgZwT4OGJJLOPqtp6O6Gh+QQ0wJVSRyTHBLg3ohcprlI255fbCQ2hHRGvAa6UOiI5JsBrw3sRRQ3bdhfYCQ2h3WugBrhS6ojkqAAHKCvIo87r0wBXSh3xHBPgdZ5eACT4isndU9gswAdBbTl464NXnFJKBYFjArxhD/yx8Efp+9xkqCyyDyT0t9c1pa0vqJRShykHBXgCAGlSTFT1Hti5AsJjITrJzqCDeUJDVQnsWhnsKpQ6IrQb4CLytIjki8iaZtN6i8hHIrLJf53YvWVCbXhvmPgz/hFxnZ2Q+yVEJtgLaDt4qPjyn/D0mfozd0r1gI7sgT8LnLnftLuBT4wxw4FP/Pe7lwjM/CMbBlxKLWG23VsDPPTsy4O6SqgqDnYlSh322g1wY8xiYO9+ky8A5vhvzwG+d2jLattxA1PY4PO3e2uAh57KQntdURDcOpQ6AkjAb0y2NZPIYOBtY8wY//0SY0yvZo8XG2NabUYRkeuB6wFSU1Mz586d26VCy8vLiY2NpcZrqPrs73yPBRT0Hs/mETcy8csfs37kz9idfnqX1n0wGuoKRcGo7fisO4kv20j2cX+gJDEjZOrqCK2r80K1tsOtrunTp2cZY8a3eMAY0+4FGAysaXa/ZL/HizuynszMTNNVCxYsaLy99o0HjflNvNn0xOXGVO0z5jfxxnz+aJfXfTCa1xVqglLbI8fa12P1a23OEqrbTOvqvFCt7XCrC1huWsnUrvZC2SMi6QD+6/wurqdLRo+bBMCynfUU1HpAXLb3gwq+Sn9rW0VhcOtQ6gjQ1QCfD8z2354NvHloyukYScvAuMLI98Xxu3fW40scAt+8AIWberIMtb/6mqb++NoGrlS360g3wpeBpcBIEdkhItcCDwCni8gm4HT//Z4TEYtc8x7uk27grZU7OS//Rqpqa2DOeYFnKQyGmjKoKQ9uDcHSMLgKoKJHv5QpdUQKa28GY8zlbTx06iGupXMGnMhP+xsyR+/lnws3MzvnFubV/hZWz4MTfhy8ul68DFxuuPrt4NVwKBgDu7Kh77iOL9O82USbUJTqdo4ZidkaEWHisCQeu+J4dsePZQNDKFj4JO+89R9yHz2Lmvzv2l9J7lfwxf8emn7LRd9B7hew9TMoyT349QXTxvfhX9NgR1bHl2noQhgWqU0oSvUARwd4g/hID09cNZ4FcWeTUrGRGctvYuDeLyh56jy8Zf4g2b0G8tcFLmgMzP8ZfHgfPDwGti1temzXKhvsHVFVDLUVsGoeIHbamtcOvEz1PphzPnz3aceeo6flLLTXu7I7vkyFvwklebgGuFI9oN0mFKc4um88R//sHnz/8ywR4bEsHPpzJqz6JWV/G8t6OYoJJhsfwvq+F/Fh+g30TevLpUk5SOFG6ifdQdiql+HTP8A179hgf/s2yMuC9ONgyCmBT2YM/Gc2iJu0+n7w9x9CZC8wPjtvXRWsfg0m3952wR/9BrYsss0tw2bYaT4vlO2GhH7dtZk6btvn9nr/D70GSx+zH4oXPt40rWEPPGW03YNXSnWrwybAAYiIw3XNuxCdxLReA3gvdgDpa57kmMqVvBZxGeWVlVyR9wapeR/ycP0lDIldzwhiOf/r8bx6Yiwpn/8Wdiy3e8d5WRhxIYv+ghk8mcr8HGJyF8CgybBvO3z7JoiLUcYHacdC+R57mXqXHUr+3v+D166D42bBUf7DBRVFNvjDY2HjexCbavd0S3dCfF/45Lfw1ZNw2xqITQnedqwqseEMbQf4iuehcAOc/SBE+AcmVBSCuO0e+Op5UFcNnsgeKVmpI9HhFeAAfcc23jxr5jkw8xwALsYOWirflk3vT+7mD9ufgRp4N+5SKqrCuXDpUXzkjqXwpZtx1VfjJomXzFn8fOsL7P5TBul12+1KY1Js8CYMgKvfYf37/8eoS39pmwxWzYOMS8BbB9u/ss0j3/4Xrv3I1vXuL+xJuOLToc8xcNGT8MRkWP0fGHMJfPkEeGtg3ZsdOxDrrbMfAEOng9v/Ui59DAo3wnl/b5qvvgbCIjq+Dbd/BRhIOgryv7XfOESaHq8oggJ/sO9cAUOm2NuVhRDdG2L7NN1vON1vbQVs+wKGd8NoWZ8XyvPtdlXqCHJYtIF3lIgQN3gc8qP34UcfwMk3c/YNf2LeDRPok5zEk+YiUio3kV67hQVpP2JhwvdY6RtKbk0Mj4Vfw1V191JWWQ171vBe4uX8bVk19+dPYvojS7n4pVye91zMzgogMh4ueRp++jVEJ8Or18C7/w/Wvg7T7oLbVsNNX0BaBvQ/Eb5+Ct68yTbBxPeHNW+0/8cYYz8QXrwEvnrCTivcbJtmsp61B1QB9u2Av42Exf/T8Q217XNweWDcVVC114Zjc7lfNN3e/nXT7YpC+/fG+AO8+XJf/8vWWrCh43V01JKH4R/Hd7wLqTGw9XN7XVEET06B3asPfV1KdbPDbw+8I0Rg4AR7AYbGwus3TQImAf8An4/LXS7Or6nnkY9fZNJRycwe3JucN9fypz2pTKz4lHs2ZVC1YTO9IoTxQ2PZWlTBr/67hl8BvaI9RHvc1Hp9TPb8jL9U/J6Ir59ka68J+Eb8mJTqOmrqfdTU+3AdfzvJn9yOJ2chWX1/QEFdBDO3PQulO5G4dNuEER5tf3lIxA5W+vKfNhzXvw0RCTbAMq+GD+6xe9p1Xlj5Mrgmw2d/swdZFz4Ao8+DlJGtb5OcRRCTDLFp8O186JcJ/Y63j+V/C3GpTfNu/RzCoiAuzQa4t842O1UW2XXE+Jt/mncl3LK42fXwQ/ZSYgyseM42W+1ZA4NObn+ZLYvhufPh+y+Ct9aev3ztf8F9SruLHrQti+0xkhEz2593ZzbEh8DxEBWyjswAb4/LfjGJiQjjvnOObpz8t8uOA44DrubMeh8ugSWfLWbatPEYY9iUX87ijQXk7q2kosZLhMfFrpIEJm/7P8TlpnCPD98jX7TyhH8jlWKKtiQwOryIM8WQ+/AMElw1JHjt0PSyyDTWuUdzbOVSXAImPJ78wZeyKOZ0rlx7PXWPZuKp2E3eib+kT/4Swla+TOSoo2xb9TEX2eac166F6b+E9GNtyLo99qfoFv7JBr24IC7dBvF5f4c+/r89fx0Mm95U7rYlMOAESBgIG96Bly6DvBW2++DAk2yIQ1NPlPpa23QEsGURkjLEfggMnnTwr1Xul1Cyzd7etbJjAb71M38ti5uahnK/bHmw+lAyBt6/235b8sTAXVshLLzt+b318Oy5MOYiiL+o++pSjqYB3kXhYYGtTyLCiNQ4RqTGtbnMntJqPli7m9p6HxFhLiLC3ER4XIS7XUR4XIzpl0BchIeNL36Fr2ATqyqjWFQ3mkhqmej9lgnuFawLG8Et1TewvTIRSux6UzzjOb58Iw/VX8vcxaM4z1XMo+ELOf6rn1InLuan3EifiFM4afX9hL/8fbuQOxzSjsUUb0Eqi2xziTsc1r4Bs16CoVPtfDEpds+2we419jLtHrsHnv1CYFfI6GZ74GU77fXOb+weckwf2LqEQZUxsHguzH6rqf28q1a+ZAMxLMJ2/eyIbf4P0a1LmkI0bzkyqO7gajmQ3KU2vPufADuW2cuBPsAK1kFtme0JpQGu2qAB3oNS4yP54cTB7c434hrbpj24zkv1ql24BMYNS6J3QhS9gY/rvXyTW4LbJWT0S2DFlky+rKzj0t6xnFpeS17BUazK3sjm0jBe9U7mi/cLgVQ8/INpERs5NmYv6d6dDN25gR31I3nLdzJ782YwZUQfJl56HynxkSxfvp3PNhXyk/AxjMp+CVxhlOwrJSHnLSQqERlzMT5vPS7AO/Ic3MlHwed/t3vf4TG2ff+L/7V7/1v9zSeTb4MP7mVg7qv2/vKnOxbgPm/TD3g0t2ul7a559Pl2b393BwK8vsb2NPLEQP5af6+ZkVC4gbiy77BnhmhH/noo321/zi+t9VPmttDQLfPi/4NHj7cfegcK8Dz/AKr8dbhG1Bx43bWVsOQhmPgziOp14HmNAV+9/falHE8DPIRFetxcktm/xfSIMDcThiY13j95RNp+c6TC1FfZu3AhL06dyu7SagByiyr5b/YQVpbVsBIhOTacpNhwhvlgz3eFPPLJRh7+uGktKXERfFY1m9sJ44cr5lBv4nnZO5UnzOWkv1rA7tJqRtTewa4d47lu6DCm9ltJXsQ41izbzsboe7iz4Ebk6fOJCPdAn2MoG3oO8dyLGC8Mnwnr3oKyPTZ0wiLw+Qxrdu4jo18CImKbEd661e5lGx8MmADT77XfDvashecugKhE+20g61nbI6e9Hjd5K2xPn5NugC8eBeOFSbfAmz8lYd+3B35BvvsUPvp1swOeAj/5HFKPOfByYPf6+xwDiYOh/3jIWQCn/ipw3d++Cec8bJvwGgLceIktzznwur99ExY/aP/uKXceeN6lj9nLrdkd65nkrbfNZKPOa2xaPOyUF9j3RELL/7VQpwF+mBMR0hOiAEhPiOKkZsG/v70VtWRvL6a4oo5BSdFkDkqk3md4a+UJ/HRlDicM7096YjSTN+SzaU85A3tHM2Hilbz0VS63vbEZuB6+8wGrSY6NYG3Nz7m37jmOc+XwhPcC/vrIWj7vPZrt0o93ay/nft8H1D12Mp7qQopSJ7GyLJ5e5ZtY2X88Y8dPgk0f2pA/frbtJ//NC/DCRfCjD2H+zeCOsOecSRxk2/V99faAa8P5W7590x7gPOWOprbxhj3hiT+1vX/qq2Dk2ZA0nMTibBtYXz5mDxaf81BTE8uiB2HBHyFpGJz1oO3r/vLl8OXjcEE7I3a99faUDWP9pxUaOh0W/cWeeje6t90rbvhgGHaq/UaRt8IGfv5a4so2H3j9DYOmsubA5J/bwWFt+fZN27S1dUnT+IQDWfmyHa38/RfsQXAn8vnst620DNvM9soV8MP50HuIffy/P4HirfCzZYHdZVuTswj6jG7qKhtkGuCqUe+YcGaMSg2Y5nELFx3fn4uOb9o7mXlM4B7/7JMH811BOYVltbhc0CcugmEpsVTUTuPzzZfz1roc3FFxXFDu5eRv7gMgoTKCUfXTGFq5i9W+Ezhr91eMp5q8iEEMyXsNds7FIHwz/BZWJF5DaXU99YOncNO3VxL9zNm4vNUw6+Wmf8K0Y+31/JvtHlV0kv2ndYfD5k9g3JUw6hz45nk7UjQuzTZhlO6yITrqHHp//gg8OAyqS+y6vHVw4ROQ9Qws+ANkXGYP7oZH28ePmwXZL8Fp9zcduG3N7pVQV9H0ITJsBix6wIbjxJ/aA6i7V4MrzO5JH3WqPXB8yh1QWXjgAK+vtXvvCQNhX66tB2zYNjSn1FbYEb7RSZC33E7b8K6to6HnUANvvf0AaAiytf4ureveCv0AL9xkD0yP/1Hg9OwX7Pti9luw8hV7nqJv/2tHStdV24Pa9dV2+ZQRba+/dBc8/z3b7HfVf9sP+x6gAa4OmsftYlRaPOzXkhMbEcbMY9ICAn/2yYNZ+U0WV547g8Ubx1JQ62VqWiw7K2rpnxhN34gwzn7kY2r27aGMaEpXx8BqO2goLiKMDfXX8m/PX3nfTODvH8RR885C0uIjGZ0Wy50RSYQVbGZ7ylTc1XvZ3v86vun7fSZu/zdjs+fi/uZ5qqNS2TXjAUxBObmjf0tsmI9MYyiacDcbd7mZWP8Fctws27Sz8E/2XDBF38FRp9swb753e9KNNtw//FXgiNQGNWW2nb5hD3mgP8D7j7fh+cF9tkth7lLbvj/jV7Zv/1u32qadfpmwezW9tn0Nj0+2gTz5dug10HZ7XP+2/fZQU2q/BbzzC7u3DPabwZWv2cFNr1xlv3mc9tumsQYb3gMElv8bJtxkm6bqquDpmXYP89Ln7AdZzkI7JmDD+/bx7V/Zv8NbA0v/SUT1sEPzJtq9Bl6/zm6zjEvhtN90bvm8LHjhYttlNjyGgDfjqnn2+tM/Nh0n2fSR3ZY7vrbhDfZ1OlCAr33Dbr+chXbekWd1vL79B8MdIhrgqkeNHdCLku/cuF3C9FGtfw2dc8NUvisoZ1hKLJEeN+FhLmIjwnC7hH2VM1j0VSbLS5Lpu88Q4XGRV1zFi19v562631FNOKUVMQC2u+V3+RhzHqlMYoLrWz6pPp7y13zAosbnS3ungPyyanwmk0FJp9A3K4rIsNGcmlxJRskCwuQo3on5BXvfWMu2okrcLsHlEuIjw7h16A8ZvvI5qta+izdlFD6Xh5ryEuKliojSrbZZB6hJGIonNg2v18feijpqzniKAR/egHz6e1vEyTfbvvzr5tuRuYjth79rJZEb34MKjz3H+gvNeqREJdoPGXcEHHUaFaf/BfJWENM/A975OTxzpj0+8N0ndv4Pf2lP4zD1Tvshsewp26yw9H/t80Ynwd4tULTZntYhcZD9IJl6l32eZ8+1e/DDTrX957d+RkbMYJg+0653yUOw/h1IHQMjzrTfJPZvZ6+vsXu6fUY3fRgaA+/cYb8lpB5j1zPkFPshV70PVr9qRzL3Pb4pBAs22m8xYy6xH2hzLrDfpBIGwAf3ETbOPxK51N9clDAQtvu7sg6dBls+s2G/ZbE9kJ042IbypFvafvOuedX+bd5ae6oMT7TdG28ezN46u+0TB9tvUBVF9hvANy/AZc+3ve4u0gBXIWdA72gG9I5u9bGEaA9Tp5/J1P2me32GbUUVdp4oD/FRHjxue9DNGENFrZei8hp+WF5LUXkNpdX1DEmOIXdvBe+s2sXRfQewd+c29kgcJZW1FFb4eL7+VFJSz8ZgWLa8mOiIUoalxILXPt/G3WWcXnom42QYV3o/ZmDeHsLwUWaiKKM3e8OPZUfiWHLz97I5vy+7f/shlXVevD77Q+KjU2/mkrHXUbRzG5tyR9Pr9W85aczjDB2TR8Xe3bz+zk4iqsYyIepitgy/juiYWEZUZBEvVaz3DeCLwkhuyP89dfEDiSio57r3EthXNZnf9DmalBOfYvLSHxP+xg344vshw89Asp6hvO90PEedRYTcDulj7YjkHcvwzb8F185vMBf/G9myCD5/BABfr8EsSb2CU8IfRfKWw/AzYPPHdk/0pJ8Q89WT8MzZNjg3vAOpGfbbwYo5tkvp5NvsqR3yVsDgyTYki7faAUqpx4AnynYv3f4lnP8P20z1+Mnw9u12T3zFc/YcQwC9h8LAiTbUN31og3TtG/aDLCIOrnnXNgn9axoZq38Hxw61B4sxcNmz8PyFENcXpt0LOWfYpqecRfaDcshUOyCu4bgEwMYP7R76STc2nh+J039nR0//Z7YdDBYWaes68wEYcCLMv8WeBwix2+LdX9hxCgMm2J5Uh1iHfpX+UBk/frxZvnx5l5ZduHAh06ZNO7QFHQKhWheEbm1OrKvO6yPMJbZ3jJ/PZ1idtw+3S0iNj+SzTQWEuV1k9EtgyeZCvswpYmthBdNH9mFQUjTZ20tIjA4nNSESr9fHnKXb2FpUwYg+cUR6XGwvrmJvRW3j+pNiwukdE07BvgqqvEJNva/xMREYmRpHfKSH5dv24jOQGO1hSHIMK3JLABgv6/ln+KM85LqGvN4n8ufCm/lr3SzeMidzbuwmvMmj8EWnsHFPGXlFJfQnH0kZSXSYYXTJYs7rvZ33KkbwYvHRXBf+PiekuvGceg9l6z7F461k2CmXsfTlvzCj4i3S6nfyYfxFzE/6MeeMSWEiq0la9SSurZ9hwiKpTxtL2M7l1PUaSu7QWQwq+RpTupP68kKiK3dSm5KBue5T/vXZNnoXfMkPNtwCxmD6ZeI6/XdQuJG6de/i3b4MiU4iYshEmPILe4qK3C/hmnepSR5Nbb2PuE1vUvfmbXjqywCBtDFw4xI7ajg8BlJGwYNH2QPj+evsh8yoc+Gp6fiik/ENmU5YRLT9EALb5dTltk1Vt6+1vVXqqu0powvW2+MJRZvtNyFvjd3zzn4JynbZgL/qjcbjH11974tIq79KrwF+kEK1Lgjd2rQuy+czVNd7iQ4Pa7y/uaCcfVV1RHncHJ0ej8sljXVV13kpra6jtKqOpJgIEmNsD5msbcU88/kWbp4xnGEpMXy6Pp/+idEM6B3F2rx9PL4oh7ySKq44aSC9oj1sKaxkW1EFWwsrKK2uZ0RqLEenJxAbGcYn6/YgYr/FfLwun6SYcO44YyRZ2/byZvZOKmu9AX+DAKPS4ymrrCE+OoLiylp27bNtym4XnBK7iw2VseyqjyNKaqg2HgwuRGzLCRiGyG5KiMUTm0x+WQ1hLiHSV0EVEXhxkxwbwYDeUeQUVLCvyg62Gj8okUFJMRSUVVNYXEJhjZuC8hpcIpx7bDrhRZuYKCsZ6i5gXa8pfFw1kg17ykiMDuf0o1P5fv18ktY+jatsF0umvszyuiFUrnmX4/a+z4mu9aRKMUtiz+T/ak7jl2lfUuNzsSbsGGIyL2NIcgy19T6+yS1haEoMkwZFs/vdBwj3VhGXcRbL5Fiic97j+GW/4NsTH2BV4mlsK6rkipMGsmX1skMa4NqEolSQuFzSGN4N9w80kjfS4ybS46ZPXOApejMHJZI5KLHx/hnNDhpPGJbMhGEH6CGzn2snD2m8XVFTj8ftIjzMxSWZ/bnvnKNZtmUvR/eNp7LWy6fr84kq2cIPzm06BYHPZ/hmezGb88vZvreKvJJ+nBMTTt9eURRX1pKWEMmAxGiythUTFxnGhKFJeH2GT9fns2zrXh64OIOj0xN4b80ufAaqauvZvreK7cWVnDwsiWsmDeHLnCIWbMjni+8KSYoNZ3B6MmMiwkhLiKK0qo7/LN9OTX0MS+JmsGtfNR63MCylinEDE9lZUsXDH2/kITMK+CsufPjer8clm8jofwIRk8/k8fUFfLerEFMfydDkGE7b1BeAKI+bqg3ftNhm4WEuausn2jtZNcAyIJkI/kXNwnBgDeFhLk4e1nYX3q7SAFdKtSomIjAeYiPCAg48Xzt5CAsXbguYx+USMgf1JnNQ7wOue8qIwPPdHzegV8D9ayYNoS0nDunNLae2fUK0e88ezWeLF3HqjOlU1tYT5nIFnPoiv6yaT9flU13nZUy/BBKiPPSJiyQh2o5O/dn04cxZupVTR/VhWEosS3OK6Ncriv6JUazZWcrufdWAIaN/L77eUsTyrcWcMjwZn4GNe8o4fmAi6QmRlNXU43G5SIzx0Dchyn6b2tXOYLFO0gBXSh1WwsNcuF32WEXzbzgN+sRFMuvEgW0uHxXu5sapTd0jJx3V9A1m7IBeMKBp3gvH9efCcU1jJM7O6Nlz0h+mY2OVUurwpwGulFIOpQGulFIOpQGulFIOpQGulFIOpQGulFIOpQGulFIOpQGulFIO1aPnQhGRAmBbuzO2LhkoPITlHCqhWheEbm1aV+eEal0QurUdbnUNMsak7D+xRwP8YIjI8tZO5hJsoVoXhG5tWlfnhGpdELq1HSl1aROKUko5lAa4Uko5lJMC/F/BLqANoVoXhG5tWlfnhGpdELq1HRF1OaYNXCmlVCAn7YErpZRqRgNcKaUcyhEBLiJnisgGEdksIncHsY4BIrJARNaJyFoRudU//X4RyRORbP/l7CDUtlVEVvuff7l/Wm8R+UhENvmvE9tbzyGuaWSzbZItIqUicluwtpeIPC0i+SKyptm0NreRiNzjf89tEJGZPVzXgyKyXkRWicgbItLLP32wiFQ123ZP9HBdbb52Qd5erzSraauIZPun9+T2aisfuu89ZowJ6QvgBr4DhgLhwErg6CDVkg4c778dB2wEjgbuB34R5O20FUjeb9pfgbv9t+8G/hLk13E3MChY2wuYAhwPrGlvG/lf15VABDDE/x5092BdZwBh/tt/aVbX4ObzBWF7tfraBXt77ff434BfB2F7tZUP3fYec8Ie+InAZmNMjjGmFpgLXBCMQowxu4wxK/y3y4B1QL9g1NJBFwBz/LfnAN8LXimcCnxnjOnqSNyDZoxZDOzdb3Jb2+gCYK4xpsYYswXYjH0v9khdxpgPjTH1/rtfAv1bLNjN2thebQnq9mogIgJcBrzcHc99IAfIh257jzkhwPsB25vd30EIhKaIDAbGAV/5J/3M/3X36Z5uqvAzwIcikiUi1/unpRpjdoF9cwF92ly6+80i8J8q2NurQVvbKJTedz8C3mt2f4iIfCMii0TklLYW6katvXahsr1OAfYYYzY1m9bj22u/fOi295gTAlxamRbUvo8iEgu8BtxmjCkFHgeGAWOBXdivcD1tkjHmeOAs4KciMiUINbRKRMKB84H/+CeFwvZqT0i870TkPqAeeNE/aRcw0BgzDvg58JKIxPdgSW29diGxvYDLCdxR6PHt1Uo+tDlrK9M6tc2cEOA7CPgdaPoDO4NUCyLiwb44LxpjXgcwxuwxxniNMT7gKbrpq+OBGGN2+q/zgTf8NewRkXR/3elAfk/X5XcWsMIYs8dfY9C3VzNtbaOgv+9EZDZwLnCF8Tea+r9uF/lvZ2HbTUf0VE0HeO1CYXuFARcBrzRM6+nt1Vo+0I3vMScE+DJguIgM8e/JzQLmB6MQf/vav4F1xpiHmk1PbzbbhcCa/Zft5rpiRCSu4Tb2ANga7Haa7Z9tNvBmT9bVTMBeUbC3137a2kbzgVkiEiEiQ4DhwNc9VZSInAncBZxvjKlsNj1FRNz+20P9deX0YF1tvXZB3V5+pwHrjTE7Gib05PZqKx/ozvdYTxydPQRHd8/GHtH9DrgviHVMxn7FWQVk+y9nA88Dq/3T5wPpPVzXUOzR7JXA2oZtBCQBnwCb/Ne9g7DNooEiIKHZtKBsL+yHyC6gDrv3c+2BthFwn/89twE4q4fr2oxtH214nz3hn/di/2u8ElgBnNfDdbX52gVze/mnPwvcuN+8Pbm92sqHbnuP6VB6pZRyKCc0oSillGqFBrhSSjmUBrhSSjmUBrhSSjmUBrhSSjmUBrhSSjmUBrhSSjnU/wdZL5VHmU40gQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Comically Deep Model\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_tr_ex))\n",
        "\n",
        "mod_ex = keras.Sequential()\n",
        "mod_ex.add(normalizer)\n",
        "mod_ex.add(InputLayer(input_shape=(start_width,)))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(1))\n",
        "\n",
        "mod_ex.compile(optimizer='adam', loss=\"mean_absolute_percentage_error\")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20, restore_best_weights=True) \n",
        "\n",
        "hist_ex = mod_ex.fit(\n",
        "  X_tr_ex,\n",
        "  y_tr_ex,\n",
        "  epochs=1000,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback],\n",
        "  verbose=0\n",
        ")\n",
        "print(mod_ex.evaluate(X_te_ex, y_te_ex))\n",
        "plot_loss(hist_ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Try Adding Dropouts\n",
        "\n",
        "We don't have a bunch of overfitting, so we may not expect miracles here... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "422/422 [==============================] - 1s 1ms/step - loss: 67.8293\n",
            "67.82926177978516\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Comically Deep Model with Dropouts\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_tr_ex))\n",
        "\n",
        "mod_ex = keras.Sequential()\n",
        "mod_ex.add(normalizer)\n",
        "mod_ex.add(InputLayer(input_shape=(start_width,)))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(1))\n",
        "\n",
        "mod_ex.compile(optimizer='adam', loss=\"mean_absolute_percentage_error\")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20, restore_best_weights=True) \n",
        "\n",
        "hist_ex = mod_ex.fit(\n",
        "  X_tr_ex,\n",
        "  y_tr_ex,\n",
        "  epochs=200,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback],\n",
        "  verbose=0\n",
        ")\n",
        "print(mod_ex.evaluate(X_te_ex, y_te_ex))\n",
        "plot_loss(hist_ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Taper Model Somewhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "422/422 [==============================] - 1s 1ms/step - loss: 7.5888 - mean_squared_error: 586385.4375 - mean_absolute_error: 309.8677 - mean_absolute_percentage_error: 7.5888\n",
            "[7.588844299316406, 586385.4375, 309.86767578125, 7.588844299316406]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Taper Deep Model\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_tr_ex))\n",
        "\n",
        "mod_ex = keras.Sequential()\n",
        "mod_ex.add(normalizer)\n",
        "mod_ex.add(InputLayer(input_shape=(start_width,)))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/2, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/2, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/2, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/2, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/2, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/3, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/3, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/3, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/3, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/4, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/4, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/4, activation='relu'))\n",
        "mod_ex.add(Dense(1))\n",
        "\n",
        "mod_ex.compile(optimizer='adam', loss=\"mean_absolute_percentage_error\", metrics=[metrics.mean_squared_error, \n",
        "                                                                        metrics.mean_absolute_error, \n",
        "                                                                        metrics.mean_absolute_percentage_error])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20, restore_best_weights=True) \n",
        "\n",
        "hist_ex = mod_ex.fit(\n",
        "  X_tr_ex,\n",
        "  y_tr_ex,\n",
        "  epochs=1000,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback],\n",
        "  verbose=1\n",
        ")\n",
        "print(mod_ex.evaluate(X_te_ex, y_te_ex))\n",
        "plot_loss(hist_ex)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "keras_optimizations_sol.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('ml3950')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
